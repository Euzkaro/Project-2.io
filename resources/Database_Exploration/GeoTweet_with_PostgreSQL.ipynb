{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project 3 - GeoTweet+\n",
    "# \n",
    "# @Author Jeffery Brown (daddyjab)\n",
    "# @Date 4/21/19\n",
    "# @File app.py\n",
    "\n",
    "\n",
    "# import necessary libraries\n",
    "import os\n",
    "from flask import Flask, render_template, jsonify, request, redirect\n",
    "\n",
    "# Import Flask_CORS extension to enable Cross Origin Resource Sharing (CORS)\n",
    "# when deployed on Heroku\n",
    "from flask_cors import CORS\n",
    "\n",
    "#################################################\n",
    "# Flask Setup\n",
    "#################################################\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Enable Tracking of Flask-SQLAlchemy events for now (probably not needed)\n",
    "app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = True\n",
    "\n",
    "# Provide cross origin resource sharing\n",
    "CORS(app)\n",
    "\n",
    "#################################################\n",
    "# Database Setup\n",
    "#################################################\n",
    "\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "from sqlalchemy.sql.expression import func, and_, or_\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "# sqlAlchemy-utc - provides a helper function utcnow() that will\n",
    "# help us set the default timestamp of when a record is created\n",
    "# using UTC time (vs. local time provided by func.now() )\n",
    "# from sqlalchemy_utc import utcnow\n",
    "\n",
    "from datetime import datetime, date, timedelta\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "#Probably don't need these from SQLAlchemy: asc, desc, between, distinct, func, null, nullsfirst, nullslast, or_, and_, not_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db.session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Local PostgreSQL database login/password is populated\n"
     ]
    }
   ],
   "source": [
    "# Import keys and other info\n",
    "# postgres_geotweetapp_login\n",
    "# postgres_geotweetapp_password\n",
    "from api_config import *\n",
    "\n",
    "\n",
    "\n",
    "#REVISED PATH HERE WITH JUPYTER NOTEBOOK RUNNING IN `resources` FOLDER: ******************************\n",
    "# db_path_flask_app = \"sqlite:///data/twitter_trends.db\"\n",
    "\n",
    "#REVISED TO SWITCH TO LOCAL DB THROUGH POSTGRESQL\n",
    "# db_path_flask_app = f\"postgresql://{postgres_geotweetapp_login}:{postgres_geotweetapp_password}@localhost/twitter_trends\"\n",
    "# app.config['SQLALCHEMY_DATABASE_URI'] = os.environ.get('DATABASE_URL', '') or db_path_flask_app\n",
    "\n",
    "\n",
    "# REVISED TO USE SQLITE BY DEFAULT, BUT USE POSTGRESQL IF ITS CONFIGURED LOCALLY\n",
    "# Local DB path for SQLite - default\n",
    "db_path_flask_app = \"sqlite:///data/twitter_trends.db\"\n",
    "\n",
    "# Local DB path for PostgreSQL - use only if login/password populated\n",
    "try:\n",
    "    # PostgreSQL Database Login/Password  \n",
    "    # -- only needed if using a local PostgresSQL instance (vs. SQLite)\n",
    "    from api_config import (postgres_geotweetapp_login, postgres_geotweetapp_password)\n",
    "\n",
    "    # If the login and password is populated\n",
    "    if (postgres_geotweetapp_login is not None) and (postgres_geotweetapp_password is not None):\n",
    "        db_path_flask_app = f\"postgresql://{postgres_geotweetapp_login}:{postgres_geotweetapp_password}@localhost/twitter_trends\"\n",
    "        print(\"Note: Local PostgreSQL database login/password is populated\")\n",
    "\n",
    "# If the api_config file is not available, then all we can do is flag an error\n",
    "except ImportError:\n",
    "    print(\"Note: Local PostgreSQL database login/password is *not* populated\")\n",
    "\n",
    "app.config['SQLALCHEMY_DATABASE_URI'] = os.environ.get('DATABASE_URL', '') or db_path_flask_app\n",
    "\n",
    "# Flask-SQLAlchemy database\n",
    "db = SQLAlchemy(app)\n",
    "\n",
    "# Import the schema for the Location and Trend tables needed for\n",
    "# 'twitter_trends.sqlite' database tables 'locations' and 'trends'\n",
    "\n",
    "#DIRECTLY ADD CODE HERE WITH JUPYTER NOTEBOOK: *****************************************\n",
    "# from .models import (Location, Trend)\n",
    "\n",
    "# Database schema for Twitter 'locations' table\n",
    "class Location(db.Model):\n",
    "    __tablename__ = 'locations'\n",
    "    \n",
    "    # Defining the columns for the table 'locations',\n",
    "    # which will hold all of the locations in the U.S. for which\n",
    "    # top trends data is available, as well as location specific\n",
    "    # info like latitude/longitude\n",
    "    id = db.Column(db.Integer, primary_key=True)\n",
    "    updated_at = db.Column( db.DateTime )\n",
    "    woeid = db.Column(db.Integer, unique=True, nullable=False)\n",
    "    twitter_country = db.Column(db.String(100))\n",
    "    tritter_country_code = db.Column(db.String(10))\n",
    "    twitter_name = db.Column(db.String(250))\n",
    "    twitter_parentid = db.Column(db.Integer)\n",
    "    twitter_type = db.Column(db.String(50))\n",
    "    country_name = db.Column(db.String(250))\n",
    "    country_name_only = db.Column(db.String(250))\n",
    "    country_woeid = db.Column(db.Integer)\n",
    "    county_name = db.Column(db.String(250))\n",
    "    county_name_only = db.Column(db.String(250))\n",
    "    county_woeid = db.Column(db.Integer)\n",
    "    latitude = db.Column(db.Float)\n",
    "    longitude = db.Column(db.Float)\n",
    "    name_full = db.Column(db.String(250))\n",
    "    name_only = db.Column(db.String(250))\n",
    "    name_woe = db.Column(db.String(250))\n",
    "    place_type = db.Column(db.String(250))\n",
    "    state_name = db.Column(db.String(250))\n",
    "    state_name_only = db.Column(db.String(250))\n",
    "    state_woeid = db.Column(db.Integer)\n",
    "    timezone = db.Column(db.String(250))\n",
    "    \n",
    "    my_trends = db.relationship('Trend', backref=db.backref('my_location', lazy=True))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        #return '<Location %r>' % (self.name_full)\n",
    "        return f\"<Location {self.name_full} [updated_at: {self.updated_at}>\"\n",
    "\n",
    "# Database schema for Twitter 'trends' table\n",
    "class Trend(db.Model):\n",
    "    __tablename__ = 'trends'\n",
    "    \n",
    "    # Defining the columns for the table 'trends',\n",
    "    # which will hold all of the top trends associated with\n",
    "    # locations in the 'locations' table\n",
    "    id = db.Column(db.Integer, primary_key=True)\n",
    "    updated_at = db.Column( db.DateTime )\n",
    "    woeid = db.Column(db.Integer, db.ForeignKey('locations.woeid') )\n",
    "    twitter_as_of = db.Column(db.String(100))\n",
    "    twitter_created_at = db.Column(db.String(100))\n",
    "    twitter_name = db.Column(db.String(250))\n",
    "    twitter_tweet_name = db.Column(db.String(250))\n",
    "    twitter_tweet_promoted_content = db.Column(db.String(250))\n",
    "    twitter_tweet_query = db.Column(db.String(250))\n",
    "    twitter_tweet_url = db.Column(db.String(250))\n",
    "    twitter_tweet_volume = db.Column(db.Float)\n",
    "\n",
    "    # locations = db.relationship('Location', backref=db.backref('trends', lazy=True))\n",
    "     \n",
    "    def __repr__(self):\n",
    "        #return '<Trend %r>' % (self.twitter_tweet_name)\n",
    "        return f\"<Trend {self.my_location.name_full}: {self.twitter_tweet_name} [updated_at: {self.updated_at}>\"\n",
    "\n",
    "#DIRECTLY ADD CODE HERE WITH JUPYTER NOTEBOOK: *****************************************\n",
    "# Initial the database on Heroku start-up\n",
    "# from python.app import db\n",
    "db.create_all()\n",
    "db.session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 4, 29, 22, 54, 37, 389064)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.utcnow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = api_calls_remaining(\"/trends/place\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'/trends/available': {'limit': 75, 'remaining': 75, 'reset': 1556586242},\n",
      " '/trends/closest': {'limit': 75, 'remaining': 75, 'reset': 1556586242},\n",
      " '/trends/place': {'limit': 75, 'remaining': 75, 'reset': 1556586242}}\n"
     ]
    }
   ],
   "source": [
    "pprint(abc['trends'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lists': {'/lists/list': {'limit': 15, 'remaining': 15, 'reset': 1556586468},\n",
       "  '/lists/memberships': {'limit': 75, 'remaining': 75, 'reset': 1556586468},\n",
       "  '/lists/subscribers/show': {'limit': 15,\n",
       "   'remaining': 15,\n",
       "   'reset': 1556586468},\n",
       "  '/lists/members': {'limit': 900, 'remaining': 900, 'reset': 1556586468},\n",
       "  '/lists/subscriptions': {'limit': 15, 'remaining': 15, 'reset': 1556586468},\n",
       "  '/lists/show': {'limit': 75, 'remaining': 75, 'reset': 1556586468},\n",
       "  '/lists/ownerships': {'limit': 15, 'remaining': 15, 'reset': 1556586468},\n",
       "  '/lists/subscribers': {'limit': 180, 'remaining': 180, 'reset': 1556586468},\n",
       "  '/lists/members/show': {'limit': 15, 'remaining': 15, 'reset': 1556586468},\n",
       "  '/lists/statuses': {'limit': 900, 'remaining': 900, 'reset': 1556586468}},\n",
       " 'application': {'/application/rate_limit_status': {'limit': 180,\n",
       "   'remaining': 170,\n",
       "   'reset': 1556586188}},\n",
       " 'mutes': {'/mutes/users/list': {'limit': 15,\n",
       "   'remaining': 15,\n",
       "   'reset': 1556586468},\n",
       "  '/mutes/users/ids': {'limit': 15, 'remaining': 15, 'reset': 1556586468}},\n",
       " 'live_video_stream': {'/live_video_stream/status/:id': {'limit': 1000,\n",
       "   'remaining': 1000,\n",
       "   'reset': 1556586468}},\n",
       " 'friendships': {'/friendships/outgoing': {'limit': 15,\n",
       "   'remaining': 15,\n",
       "   'reset': 1556586468},\n",
       "  '/friendships/list': {'limit': 200, 'remaining': 200, 'reset': 1556586468},\n",
       "  '/friendships/no_retweets/ids': {'limit': 15,\n",
       "   'remaining': 15,\n",
       "   'reset': 1556586468},\n",
       "  '/friendships/lookup': {'limit': 15, 'remaining': 15, 'reset': 1556586468},\n",
       "  '/friendships/incoming': {'limit': 15, 'remaining': 15, 'reset': 1556586468},\n",
       "  '/friendships/show': {'limit': 180, 'remaining': 180, 'reset': 1556586468}},\n",
       " 'guide': {'/guide': {'limit': 180, 'remaining': 180, 'reset': 1556586468}},\n",
       " 'auth': {'/auth/csrf_token': {'limit': 15,\n",
       "   'remaining': 15,\n",
       "   'reset': 1556586468}},\n",
       " 'blocks': {'/blocks/list': {'limit': 15,\n",
       "   'remaining': 15,\n",
       "   'reset': 1556586468},\n",
       "  '/blocks/ids': {'limit': 15, 'remaining': 15, 'reset': 1556586468}},\n",
       " 'geo': {'/geo/similar_places': {'limit': 15,\n",
       "   'remaining': 15,\n",
       "   'reset': 1556586468},\n",
       "  '/geo/id/:place_id': {'limit': 75, 'remaining': 75, 'reset': 1556586468},\n",
       "  '/geo/reverse_geocode': {'limit': 15, 'remaining': 15, 'reset': 1556586468},\n",
       "  '/geo/search': {'limit': 15, 'remaining': 15, 'reset': 1556586468}},\n",
       " 'users': {'/users/report_spam': {'limit': 15,\n",
       "   'remaining': 15,\n",
       "   'reset': 1556586468},\n",
       "  '/users/contributors/pending': {'limit': 2000,\n",
       "   'remaining': 2000,\n",
       "   'reset': 1556586468},\n",
       "  '/users/show/:id': {'limit': 900, 'remaining': 900, 'reset': 1556586468},\n",
       "  '/users/search': {'limit': 900, 'remaining': 900, 'reset': 1556586468},\n",
       "  '/users/suggestions/:slug': {'limit': 15,\n",
       "   'remaining': 15,\n",
       "   'reset': 1556586468},\n",
       "  '/users/contributees/pending': {'limit': 200,\n",
       "   'remaining': 200,\n",
       "   'reset': 1556586468},\n",
       "  '/users/derived_info': {'limit': 15, 'remaining': 15, 'reset': 1556586468},\n",
       "  '/users/profile_banner': {'limit': 180,\n",
       "   'remaining': 180,\n",
       "   'reset': 1556586468},\n",
       "  '/users/suggestions/:slug/members': {'limit': 15,\n",
       "   'remaining': 15,\n",
       "   'reset': 1556586468},\n",
       "  '/users/lookup': {'limit': 900, 'remaining': 900, 'reset': 1556586468},\n",
       "  '/users/suggestions': {'limit': 15, 'remaining': 15, 'reset': 1556586468}},\n",
       " 'followers': {'/followers/ids': {'limit': 15,\n",
       "   'remaining': 15,\n",
       "   'reset': 1556586468},\n",
       "  '/followers/list': {'limit': 15, 'remaining': 15, 'reset': 1556586468}},\n",
       " 'collections': {'/collections/list': {'limit': 1000,\n",
       "   'remaining': 1000,\n",
       "   'reset': 1556586468},\n",
       "  '/collections/entries': {'limit': 1000,\n",
       "   'remaining': 1000,\n",
       "   'reset': 1556586468},\n",
       "  '/collections/show': {'limit': 1000,\n",
       "   'remaining': 1000,\n",
       "   'reset': 1556586468}},\n",
       " 'statuses': {'/statuses/retweeters/ids': {'limit': 75,\n",
       "   'remaining': 75,\n",
       "   'reset': 1556586468},\n",
       "  '/statuses/retweets_of_me': {'limit': 75,\n",
       "   'remaining': 75,\n",
       "   'reset': 1556586468},\n",
       "  '/statuses/home_timeline': {'limit': 15,\n",
       "   'remaining': 15,\n",
       "   'reset': 1556586468},\n",
       "  '/statuses/show/:id': {'limit': 900, 'remaining': 900, 'reset': 1556586468},\n",
       "  '/statuses/user_timeline': {'limit': 900,\n",
       "   'remaining': 900,\n",
       "   'reset': 1556586468},\n",
       "  '/statuses/friends': {'limit': 15, 'remaining': 15, 'reset': 1556586468},\n",
       "  '/statuses/retweets/:id': {'limit': 75,\n",
       "   'remaining': 75,\n",
       "   'reset': 1556586468},\n",
       "  '/statuses/mentions_timeline': {'limit': 75,\n",
       "   'remaining': 75,\n",
       "   'reset': 1556586468},\n",
       "  '/statuses/oembed': {'limit': 180, 'remaining': 180, 'reset': 1556586468},\n",
       "  '/statuses/lookup': {'limit': 900, 'remaining': 900, 'reset': 1556586468}},\n",
       " 'custom_profiles': {'/custom_profiles/list': {'limit': 180,\n",
       "   'remaining': 180,\n",
       "   'reset': 1556586468},\n",
       "  '/custom_profiles/show': {'limit': 180,\n",
       "   'remaining': 180,\n",
       "   'reset': 1556586468}},\n",
       " 'webhooks': {'/webhooks/subscriptions/direct_messages': {'limit': 15,\n",
       "   'remaining': 15,\n",
       "   'reset': 1556586468},\n",
       "  '/webhooks': {'limit': 15, 'remaining': 15, 'reset': 1556586468}},\n",
       " 'contacts': {'/contacts/uploaded_by': {'limit': 300,\n",
       "   'remaining': 300,\n",
       "   'reset': 1556586468},\n",
       "  '/contacts/users': {'limit': 300, 'remaining': 300, 'reset': 1556586468},\n",
       "  '/contacts/addressbook': {'limit': 300,\n",
       "   'remaining': 300,\n",
       "   'reset': 1556586468},\n",
       "  '/contacts/users_and_uploaded_by': {'limit': 300,\n",
       "   'remaining': 300,\n",
       "   'reset': 1556586468},\n",
       "  '/contacts/delete/status': {'limit': 300,\n",
       "   'remaining': 300,\n",
       "   'reset': 1556586468}},\n",
       " 'labs': {'/labs/:version/users': {'limit': 3000,\n",
       "   'remaining': 3000,\n",
       "   'reset': 1556586468},\n",
       "  '/labs/:version/tweets': {'limit': 3000,\n",
       "   'remaining': 3000,\n",
       "   'reset': 1556586468}},\n",
       " 'i': {'/i/config': {'limit': 15, 'remaining': 15, 'reset': 1556586468}},\n",
       " 'tweet_prompts': {'/tweet_prompts/report_interaction': {'limit': 180,\n",
       "   'remaining': 180,\n",
       "   'reset': 1556586468},\n",
       "  '/tweet_prompts/show': {'limit': 180,\n",
       "   'remaining': 180,\n",
       "   'reset': 1556586468}},\n",
       " 'moments': {'/moments/statuses/update': {'limit': 5,\n",
       "   'remaining': 5,\n",
       "   'reset': 1556586468},\n",
       "  '/moments/permissions': {'limit': 300,\n",
       "   'remaining': 300,\n",
       "   'reset': 1556586468}},\n",
       " 'help': {'/help/tos': {'limit': 15, 'remaining': 15, 'reset': 1556586468},\n",
       "  '/help/configuration': {'limit': 15, 'remaining': 15, 'reset': 1556586468},\n",
       "  '/help/privacy': {'limit': 15, 'remaining': 15, 'reset': 1556586468},\n",
       "  '/help/settings': {'limit': 15, 'remaining': 15, 'reset': 1556586468},\n",
       "  '/help/languages': {'limit': 15, 'remaining': 15, 'reset': 1556586468}},\n",
       " 'feedback': {'/feedback/show/:id': {'limit': 180,\n",
       "   'remaining': 180,\n",
       "   'reset': 1556586468},\n",
       "  '/feedback/events': {'limit': 1000, 'remaining': 1000, 'reset': 1556586468}},\n",
       " 'business_experience': {'/business_experience/dashboard_settings/destroy': {'limit': 450,\n",
       "   'remaining': 450,\n",
       "   'reset': 1556586468},\n",
       "  '/business_experience/dashboard_features': {'limit': 450,\n",
       "   'remaining': 450,\n",
       "   'reset': 1556586468},\n",
       "  '/business_experience/keywords': {'limit': 450,\n",
       "   'remaining': 450,\n",
       "   'reset': 1556586468},\n",
       "  '/business_experience/dashboard_settings/update': {'limit': 450,\n",
       "   'remaining': 450,\n",
       "   'reset': 1556586468},\n",
       "  '/business_experience/dashboard_settings/show': {'limit': 450,\n",
       "   'remaining': 450,\n",
       "   'reset': 1556586468}},\n",
       " 'graphql&POST': {'/graphql&POST': {'limit': 2500,\n",
       "   'remaining': 2500,\n",
       "   'reset': 1556586468}},\n",
       " 'friends': {'/friends/following/ids': {'limit': 15,\n",
       "   'remaining': 15,\n",
       "   'reset': 1556586468},\n",
       "  '/friends/following/list': {'limit': 15,\n",
       "   'remaining': 15,\n",
       "   'reset': 1556586468},\n",
       "  '/friends/list': {'limit': 15, 'remaining': 15, 'reset': 1556586468},\n",
       "  '/friends/ids': {'limit': 15, 'remaining': 15, 'reset': 1556586468}},\n",
       " 'sandbox': {'/sandbox/account_activity/webhooks/:id/subscriptions': {'limit': 500,\n",
       "   'remaining': 500,\n",
       "   'reset': 1556586468}},\n",
       " 'drafts': {'/drafts/statuses/update': {'limit': 450,\n",
       "   'remaining': 450,\n",
       "   'reset': 1556586468},\n",
       "  '/drafts/statuses/destroy': {'limit': 450,\n",
       "   'remaining': 450,\n",
       "   'reset': 1556586468},\n",
       "  '/drafts/statuses/ids': {'limit': 450,\n",
       "   'remaining': 450,\n",
       "   'reset': 1556586468},\n",
       "  '/drafts/statuses/list': {'limit': 450,\n",
       "   'remaining': 450,\n",
       "   'reset': 1556586468},\n",
       "  '/drafts/statuses/show': {'limit': 450,\n",
       "   'remaining': 450,\n",
       "   'reset': 1556586468},\n",
       "  '/drafts/statuses/create': {'limit': 450,\n",
       "   'remaining': 450,\n",
       "   'reset': 1556586468}},\n",
       " 'direct_messages': {'/direct_messages/sent': {'limit': 300,\n",
       "   'remaining': 300,\n",
       "   'reset': 1556586468},\n",
       "  '/direct_messages/broadcasts/list': {'limit': 60,\n",
       "   'remaining': 60,\n",
       "   'reset': 1556586468},\n",
       "  '/direct_messages/subscribers/lists/members/show': {'limit': 1000,\n",
       "   'remaining': 1000,\n",
       "   'reset': 1556586468},\n",
       "  '/direct_messages/mark_read': {'limit': 1000,\n",
       "   'remaining': 1000,\n",
       "   'reset': 1556586468},\n",
       "  '/direct_messages/subscribers/ids': {'limit': 180,\n",
       "   'remaining': 180,\n",
       "   'reset': 1556586468},\n",
       "  '/direct_messages/sent_and_received': {'limit': 300,\n",
       "   'remaining': 300,\n",
       "   'reset': 1556586468},\n",
       "  '/direct_messages/broadcasts/statuses/list': {'limit': 60,\n",
       "   'remaining': 60,\n",
       "   'reset': 1556586468},\n",
       "  '/direct_messages': {'limit': 300, 'remaining': 300, 'reset': 1556586468},\n",
       "  '/direct_messages/subscribers/lists/members/ids': {'limit': 180,\n",
       "   'remaining': 180,\n",
       "   'reset': 1556586468},\n",
       "  '/direct_messages/subscribers/show': {'limit': 180,\n",
       "   'remaining': 180,\n",
       "   'reset': 1556586468},\n",
       "  '/direct_messages/broadcasts/show': {'limit': 60,\n",
       "   'remaining': 60,\n",
       "   'reset': 1556586468},\n",
       "  '/direct_messages/broadcasts/statuses/show': {'limit': 60,\n",
       "   'remaining': 60,\n",
       "   'reset': 1556586468},\n",
       "  '/direct_messages/subscribers/lists/list': {'limit': 180,\n",
       "   'remaining': 180,\n",
       "   'reset': 1556586468},\n",
       "  '/direct_messages/show': {'limit': 300,\n",
       "   'remaining': 300,\n",
       "   'reset': 1556586468},\n",
       "  '/direct_messages/events/list': {'limit': 15,\n",
       "   'remaining': 15,\n",
       "   'reset': 1556586468},\n",
       "  '/direct_messages/subscribers/lists/show': {'limit': 180,\n",
       "   'remaining': 180,\n",
       "   'reset': 1556586468},\n",
       "  '/direct_messages/events/show': {'limit': 15,\n",
       "   'remaining': 15,\n",
       "   'reset': 1556586468}},\n",
       " 'media': {'/media/upload': {'limit': 500,\n",
       "   'remaining': 500,\n",
       "   'reset': 1556586468}},\n",
       " 'traffic': {'/traffic/map': {'limit': 15,\n",
       "   'remaining': 15,\n",
       "   'reset': 1556586468}},\n",
       " 'account_activity': {'/account_activity/all/webhooks': {'limit': 15,\n",
       "   'remaining': 15,\n",
       "   'reset': 1556586468},\n",
       "  '/account_activity/all/:instance_name/subscriptions': {'limit': 500,\n",
       "   'remaining': 500,\n",
       "   'reset': 1556586468},\n",
       "  '/account_activity/direct_messages/webhooks': {'limit': 15,\n",
       "   'remaining': 15,\n",
       "   'reset': 1556586468},\n",
       "  '/account_activity/webhooks/:id/subscriptions/direct_messages/list': {'limit': 15,\n",
       "   'remaining': 15,\n",
       "   'reset': 1556586468},\n",
       "  '/account_activity/webhooks/:id/subscriptions/all': {'limit': 500,\n",
       "   'remaining': 500,\n",
       "   'reset': 1556586468},\n",
       "  '/account_activity/direct_messages/:instance_name/webhooks': {'limit': 15,\n",
       "   'remaining': 15,\n",
       "   'reset': 1556586468},\n",
       "  '/account_activity/webhooks/:id/subscriptions/all/list': {'limit': 15,\n",
       "   'remaining': 15,\n",
       "   'reset': 1556586468},\n",
       "  '/account_activity/webhooks/:id/subscriptions/direct_messages': {'limit': 500,\n",
       "   'remaining': 500,\n",
       "   'reset': 1556586468},\n",
       "  '/account_activity/webhooks': {'limit': 15,\n",
       "   'remaining': 15,\n",
       "   'reset': 1556586468},\n",
       "  '/account_activity/direct_messages/:instance_name/subscriptions': {'limit': 15,\n",
       "   'remaining': 15,\n",
       "   'reset': 1556586468},\n",
       "  '/account_activity/webhooks/:id/subscriptions': {'limit': 500,\n",
       "   'remaining': 500,\n",
       "   'reset': 1556586468},\n",
       "  '/account_activity/all/:instance_name/webhooks': {'limit': 15,\n",
       "   'remaining': 15,\n",
       "   'reset': 1556586468}},\n",
       " 'account': {'/account/login_verification_enrollment': {'limit': 15,\n",
       "   'remaining': 15,\n",
       "   'reset': 1556586468},\n",
       "  '/account/update_profile': {'limit': 15,\n",
       "   'remaining': 15,\n",
       "   'reset': 1556586468},\n",
       "  '/account/verify_credentials': {'limit': 75,\n",
       "   'remaining': 75,\n",
       "   'reset': 1556586468},\n",
       "  '/account/settings': {'limit': 15, 'remaining': 15, 'reset': 1556586468}},\n",
       " 'safety': {'/safety/detection_feedback': {'limit': 450000,\n",
       "   'remaining': 450000,\n",
       "   'reset': 1556586468}},\n",
       " 'favorites': {'/favorites/list': {'limit': 75,\n",
       "   'remaining': 75,\n",
       "   'reset': 1556586468}},\n",
       " 'device': {'/device/token': {'limit': 15,\n",
       "   'remaining': 15,\n",
       "   'reset': 1556586468}},\n",
       " 'tweets': {'/tweets/stream/filter/rules': {'limit': 450,\n",
       "   'remaining': 450,\n",
       "   'reset': 1556586468},\n",
       "  '/tweets/stream/filter/:instance_name': {'limit': 50,\n",
       "   'remaining': 50,\n",
       "   'reset': 1556586468},\n",
       "  '/tweets/search/:product/:label': {'limit': 1800,\n",
       "   'remaining': 1800,\n",
       "   'reset': 1556586468},\n",
       "  '/tweets/search/:product/:instance/counts': {'limit': 900,\n",
       "   'remaining': 900,\n",
       "   'reset': 1556586468},\n",
       "  '/tweets/stream/filter/rules/:instance_name/validation&POST': {'limit': 450,\n",
       "   'remaining': 450,\n",
       "   'reset': 1556586468},\n",
       "  '/tweets/stream/filter/rules/:instance_name&POST': {'limit': 450,\n",
       "   'remaining': 450,\n",
       "   'reset': 1556586468},\n",
       "  '/tweets/stream/filter/rules/:instance_name&DELETE': {'limit': 450,\n",
       "   'remaining': 450,\n",
       "   'reset': 1556586468},\n",
       "  '/tweets/stream/filter/rules/:instance_name/:rule_id': {'limit': 450,\n",
       "   'remaining': 450,\n",
       "   'reset': 1556586468}},\n",
       " 'saved_searches': {'/saved_searches/destroy/:id': {'limit': 15,\n",
       "   'remaining': 15,\n",
       "   'reset': 1556586468},\n",
       "  '/saved_searches/show/:id': {'limit': 15,\n",
       "   'remaining': 15,\n",
       "   'reset': 1556586468},\n",
       "  '/saved_searches/list': {'limit': 15, 'remaining': 15, 'reset': 1556586468}},\n",
       " 'oauth': {'/oauth/invalidate_token': {'limit': 450,\n",
       "   'remaining': 450,\n",
       "   'reset': 1556586468}},\n",
       " 'search': {'/search/tweets': {'limit': 180,\n",
       "   'remaining': 180,\n",
       "   'reset': 1556586468}},\n",
       " 'trends': {'/trends/closest': {'limit': 75,\n",
       "   'remaining': 75,\n",
       "   'reset': 1556586468},\n",
       "  '/trends/available': {'limit': 75, 'remaining': 75, 'reset': 1556586468},\n",
       "  '/trends/place': {'limit': 75, 'remaining': 75, 'reset': 1556586468}},\n",
       " 'live_pipeline': {'/live_pipeline/events': {'limit': 180,\n",
       "   'remaining': 180,\n",
       "   'reset': 1556586468}}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_rate_limits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import database management functions needed to update the\n",
    "# 'twitter_trends.sqlite' database tables 'locations' and 'trends'\n",
    "\n",
    "#DIRECTLY ADD CODE HERE WITH JUPYTER NOTEBOOK: *****************************************\n",
    "# from .db_management import (\n",
    "#     api_calls_remaining, api_time_before_reset,\n",
    "#     update_db_locations_table, update_db_trends_table\n",
    "#     )\n",
    "\n",
    "# This file contains function which update the\n",
    "# 'tritter_trends.sqlite' database tables\n",
    "# 'locations' and 'trends' via API calls to Twitter and Flickr\n",
    "\n",
    "# The following dependencies are only required for update/mgmt of\n",
    "# 'locations' and 'trends' data, not for reading the data\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import tz\n",
    "import requests\n",
    "from pprint import pprint\n",
    "\n",
    "# Import a pointer to the Flask-SQLAlchemy database session\n",
    "# created in the main app.py file\n",
    "# from app import db, Location, Trend\n",
    "\n",
    "#DIRECTLY ADD CODE HERE WITH JUPYTER NOTEBOOK: *****************************************\n",
    "# from .app import db, app\n",
    "# from .models import Location, Trend\n",
    "\n",
    "# Only perform import if this is being run locally.\n",
    "# If being run from Heroku the keys will be provided\n",
    "# via the app environment variables configured there\n",
    "\n",
    "try:\n",
    "    # This will run if the keys are all set via Heroku environment\n",
    "\n",
    "    # Twitter API\n",
    "    key_twitter_tweetquestor_consumer_api_key = os.environ['key_twitter_tweetquestor_consumer_api_key']\n",
    "    key_twitter_tweetquestor_consumer_api_secret_key = os.environ['key_twitter_tweetquestor_consumer_api_secret_key']\n",
    "    key_twitter_tweetquestor_access_token = os.environ['key_twitter_tweetquestor_access_token']\n",
    "    key_twitter_tweetquestor_access_secret_token = os.environ['key_twitter_tweetquestor_access_secret_token']\n",
    "\n",
    "    # Flickr API\n",
    "    key_flicker_infoquestor_key = os.environ['key_flicker_infoquestor_key']\n",
    "    key_flicker_infoquestor_secret = os.environ['key_flicker_infoquestor_secret']\n",
    "\n",
    "except KeyError:\n",
    "    # Keys have not been set in the environment\n",
    "    # So need to import them locally\n",
    "    try:\n",
    "        # Twitter API keys\n",
    "        # Flickr API keys\n",
    "        from api_config import *\n",
    "\n",
    "    # If the api_config file is not available, then all we can do is flag an error\n",
    "    except ImportError:\n",
    "        print(\"Import Keys: At least one of the API Keys has not been populated on Heroku, and api_config not available!\")\n",
    "\n",
    "# Setup Tweepy API Authentication to access Twitter\n",
    "import tweepy\n",
    "\n",
    "try:\n",
    "    auth = tweepy.OAuthHandler(key_twitter_tweetquestor_consumer_api_key, key_twitter_tweetquestor_consumer_api_secret_key)\n",
    "    auth.set_access_token(key_twitter_tweetquestor_access_token, key_twitter_tweetquestor_access_secret_token)\n",
    "    api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())\n",
    "\n",
    "except TweepError:\n",
    "    print(\"Authentication error: Problem authenticating Twitter API using Tweepy (TweepError)\")\n",
    "    \n",
    "# # Function Definitions: Twitter API Rate Limit Management\n",
    "\n",
    "def api_rate_limits():\n",
    "# Return the number of Twitter API calls remaining\n",
    "# for the specified API type:\n",
    "# \"trends/place\": Top 10 trending topics for a WOEID\n",
    "# \"trends/closest\": Locations near a specificed lat/long for which Twitter has trending topic info\n",
    "# \"trends/available\": Locations for which Twitter has topic info\n",
    "# \"search/tweets\": \n",
    "# \"users/search\"\n",
    "# \"users/shows\"\n",
    "# \"users/lookup\"\n",
    "# \n",
    "# Global Variable: 'api': Tweepy API\n",
    "# \n",
    "\n",
    "    # Get Twitter rate limit information using the Tweepy API\n",
    "    try:\n",
    "        rate_limits = api.rate_limit_status()\n",
    "        \n",
    "    except:\n",
    "        print(\"Tweepy API: Problem getting Twitter rate limits information using tweepy\")\n",
    "\n",
    "    # Return the remaining requests available for the\n",
    "    # requested type of trends query (or \"\" if not a valid type)\n",
    "    try:\n",
    "        return rate_limits['resources']\n",
    "\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def api_calls_remaining( a_type = \"place\"):\n",
    "# Return the number of Twitter API calls remaining\n",
    "# for the specified API type:\n",
    "# 'place': Top 10 trending topics for a WOEID\n",
    "# 'closest': Locations near a specificed lat/long for which Twitter has trending topic info\n",
    "# 'available': Locations for which Twitter has topic info\n",
    "# \n",
    "# Global Variable: 'api': Tweepy API\n",
    "# \n",
    "\n",
    "    # Get Twitter rate limit information using the Tweepy API\n",
    "    rate_limits = api.rate_limit_status()\n",
    "    \n",
    "    # Focus on the rate limits for trends calls\n",
    "    trends_limits = rate_limits['resources']['trends']\n",
    "    \n",
    "    # Return the remaining requests available for the\n",
    "    # requested type of trends query (or \"\" if not a valid type)\n",
    "    try:\n",
    "        remaining = trends_limits[ f\"/trends/{a_type}\" ]['remaining']\n",
    "        print(f\"Twitter API 'trends/{a_type}' - API Calls Remaining: {remaining}\")\n",
    "\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "    return remaining\n",
    "\n",
    "\n",
    "def api_time_before_reset( a_type = \"place\"):\n",
    "# Return the number of minutes until the Twitter API is reset\n",
    "# for the specified API type:\n",
    "# 'place': Top 10 trending topics for a WOEID\n",
    "# 'closest': Locations near a specificed lat/long for which Twitter has trending topic info\n",
    "# 'available': Locations for which Twitter has topic info\n",
    "# \n",
    "# Global Variable: 'api': Tweepy API\n",
    "# \n",
    "\n",
    "    # Get Twitter rate limit information using the Tweepy API\n",
    "    rate_limits = api.rate_limit_status()\n",
    "    \n",
    "    # Focus on the rate limits for trends calls\n",
    "    trends_limits = rate_limits['resources']['trends']\n",
    "    \n",
    "    \n",
    "    # Return the reset time for the\n",
    "    # requested type of trends query (or \"\" if not a valid type)\n",
    "    try:\n",
    "        reset_ts = trends_limits[ f\"/trends/{a_type}\" ]['reset']\n",
    "    except:\n",
    "        return -1\n",
    "        \n",
    "    # Calculate the remaining time using datetime methods to\n",
    "    # get the UTC time from the POSIX timestamp\n",
    "    reset_utc = datetime.utcfromtimestamp(reset_ts)\n",
    "    \n",
    "    # Current the current time\n",
    "    current_utc = datetime.utcnow()\n",
    "    \n",
    "    # Calculate the number of seconds remaining,\n",
    "    # Assumption: reset time will be >= current time\n",
    "    time_before_reset = (reset_utc - current_utc).total_seconds() / 60.0\n",
    "    \n",
    "    # Tell the datetime object that it's in UTC time zone since \n",
    "    # datetime objects are 'naive' by default\n",
    "    reset_utc = reset_utc.replace(tzinfo = tz.tzutc() )\n",
    "    \n",
    "    # Convert time zone\n",
    "    reset_local = reset_utc.astimezone( tz.tzlocal() )\n",
    "\n",
    "    # Tell the datetime object that it's in UTC time zone since \n",
    "    # datetime objects are 'naive' by default\n",
    "    current_utc = current_utc.replace(tzinfo = tz.tzutc() )\n",
    "    \n",
    "    # Convert time zone\n",
    "    current_local = current_utc.astimezone( tz.tzlocal() )\n",
    "    print(f\"Twitter API 'trends/{a_type}' - Time Before Rate Limit Reset: {time_before_reset:.1f}: Reset Time: {reset_local.strftime('%Y-%m-%d %H:%M:%S')}, Local Time: {current_local.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    # Return the time before reset (in minutes)\n",
    "    return time_before_reset\n",
    "\n",
    "\n",
    "# # Function Definitions: Twitter Locations with Available Trends Info\n",
    "\n",
    "def get_loc_with_trends_available_to_df( ):\n",
    "# Get locations that have trends data from a api.trends_available() call,\n",
    "# flatten the data, and create a dataframe\n",
    "\n",
    "    # Obtain the WOEID locations for which Twitter Trends info is available\n",
    "    try:\n",
    "        trends_avail = api.trends_available()\n",
    "        \n",
    "    except:\n",
    "        # No locations info available, return False\n",
    "        print(f\"Tweepy API: Problem getting locations that have trends available information\")\n",
    "        return False\n",
    "    \n",
    "    # Import trend availability info into a dataframe\n",
    "    trends_avail_df = pd.DataFrame.from_dict(trends_avail, orient='columns')\n",
    "    \n",
    "    # Set the 'updated_at' column to the current time in UTC timezone for all locations\n",
    "    trends_avail_df['updated_at'] = datetime.utcnow()\n",
    "\n",
    "    # Retain only locations in the U.S.\n",
    "    trends_avail_df = trends_avail_df[ (trends_avail_df['countryCode'] == \"US\") ]\n",
    "        \n",
    "    # Reset the index\n",
    "    trends_avail_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Flatten the dataframe by unpacking the placeType column information into separate columns\n",
    "    trends_avail_df['twitter_type'] = trends_avail_df['placeType'].map( lambda x: x['name'])\n",
    "\n",
    "    # Remove unneeded fields\n",
    "    trends_avail_df.drop(['placeType', 'url' ], axis='columns' , inplace = True)\n",
    "\n",
    "    # Rename the fields\n",
    "    trends_avail_df.rename(columns={\n",
    "        'woeid': 'woeid',\n",
    "        'country': 'twitter_country',\n",
    "        'countryCode': 'tritter_country_code',\n",
    "        'name': 'twitter_name',\n",
    "        'parentid': 'twitter_parentid' }, inplace=True)\n",
    "    \n",
    "    return trends_avail_df\n",
    "\n",
    "\n",
    "\n",
    "def get_location_info( a_woeid ):\n",
    "# Use Flickr API call to get location information associated with a Yahoo! WOEID\n",
    "# Note: Yahoo! no longer supports this type of lookup! :(\n",
    "\n",
    "    # Setup the Flickr API base URL\n",
    "    flickr_api_base_url = f\"https://api.flickr.com/services/rest/?method=flickr.places.getInfo&api_key={key_flicker_infoquestor_key}&format=json&nojsoncallback=1&woe_id=\"\n",
    "\n",
    "    # Populate the WOEID and convert to string format\n",
    "    woeid_to_search = str(a_woeid)\n",
    "    \n",
    "    # Build the full URL for API REST request\n",
    "    flickr_api_url = flickr_api_base_url + woeid_to_search\n",
    "\n",
    "    try:\n",
    "        # Get the REST response, which will be in JSON format\n",
    "        response = requests.get(url=flickr_api_url)\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Flickr API: Problem getting location information for WOEID {a_woeid}: \")\n",
    "        return False\n",
    "    \n",
    "    # Parse the json\n",
    "    location_data = response.json()\n",
    "    \n",
    "    # Check for failure to locate the information\n",
    "    if (location_data['stat'] == 'fail'):\n",
    "        print(f\"Flickr API: Problem finding location WOEID {a_woeid}: {location_data['message']}\")\n",
    "        \n",
    "        \n",
    "    #pprint(location_data)\n",
    "    \n",
    "    # Return just a useful subset of the location info as flattened dictionary\n",
    "    key_location_info = {}\n",
    "    \n",
    "    # Basic information that should be present for any location\n",
    "    try:\n",
    "        key_location_info.update( {\n",
    "            'woeid': int(location_data['place']['woeid']),\n",
    "            'name_woe': location_data['place']['woe_name'],\n",
    "            'name_full': location_data['place']['name'],\n",
    "            'name_only': location_data['place']['name'].split(\",\")[0].strip(),\n",
    "            'place_type': location_data['place']['place_type'],\n",
    "            'latitude': float(location_data['place']['latitude']),\n",
    "            'longitude': float(location_data['place']['longitude']),\n",
    "        })\n",
    "                \n",
    "    except:\n",
    "        print(\"Error - basic location information not returned for WOEID{a_woeid}: \", sys.exc_info()[0])\n",
    "    \n",
    "    # Timezone associated with the location - if available\n",
    "    try:\n",
    "        key_location_info.update( {\n",
    "            'timezone': location_data['place']['timezone']  \n",
    "        })\n",
    "        \n",
    "    except:\n",
    "        key_location_info.update( {\n",
    "            'timezone': None\n",
    "        })\n",
    "        \n",
    "    # County associated with the location - if available\n",
    "    try:\n",
    "        key_location_info.update( {\n",
    "            'county_name': location_data['place']['county']['_content'],\n",
    "            'county_name_only': location_data['place']['county']['_content'].split(\",\")[0].strip(),\n",
    "            'county_woeid': int(location_data['place']['county']['woeid']),\n",
    "        })\n",
    "    except:\n",
    "        key_location_info.update( {\n",
    "            'county_name': None,\n",
    "            'county_name_only': None,\n",
    "            'county_woeid': None,\n",
    "        })\n",
    "        \n",
    "    # State associated with the location - if available\n",
    "    try:\n",
    "        key_location_info.update( {\n",
    "            'state_name': location_data['place']['region']['_content'],\n",
    "            'state_name_only': location_data['place']['region']['_content'].split(\",\")[0].strip(),\n",
    "            'state_woeid': int(location_data['place']['region']['woeid']),\n",
    "        })\n",
    "    except:\n",
    "        key_location_info.update( {\n",
    "            'state_name': None,\n",
    "            'state_name_only': None,\n",
    "            'state_woeid': None,\n",
    "        })\n",
    "        \n",
    "    # Country associated with the location - if available\n",
    "    try:\n",
    "        key_location_info.update( {\n",
    "            'country_name': location_data['place']['country']['_content'],\n",
    "            'country_name_only': location_data['place']['country']['_content'].split(\",\")[0].strip(),\n",
    "            'country_woeid': int(location_data['place']['country']['woeid']),\n",
    "        })\n",
    "    except:\n",
    "        key_location_info.update( {\n",
    "            'country_name': None,\n",
    "            'country_name_only': None,\n",
    "            'country_woeid': None, \n",
    "        })\n",
    "    \n",
    "    return key_location_info\n",
    "\n",
    "\n",
    "def update_db_locations_table():\n",
    "# Function to update the list of Twitter locations in the'locations' DB table.\n",
    "# This function uses a Twitter API to get the list of locations for which top trends\n",
    "# information is available.  It then uses a Flickr API to obtain location details for\n",
    "# each of these Twitter specified locations.  A merge is then performed of the two\n",
    "# DataFrames, resulting in a single dataframe that is used to update the 'locations' table.\n",
    "# NOTE: The Twitter 'trends/available' API call is not rate limited.\n",
    "#\n",
    "# This function assumes that the 'locations' table in the database has already been configured\n",
    "# and is ready for data.\n",
    "\n",
    "    # Flatten the Twitter Trends results and populate in a Dataframe\n",
    "    loc_with_trends_available_df = get_loc_with_trends_available_to_df( )\n",
    "\n",
    "    # Use the get_location_info() function to add location info (from Flickr)\n",
    "    # for each location (Twitter WOEID) that has trend info\n",
    "    loc_info_list =  list( loc_with_trends_available_df['woeid'].apply( get_location_info ) )\n",
    "\n",
    "    # Create a DataFrame from the location info list\n",
    "    loc_info_df = pd.DataFrame.from_dict(loc_info_list)\n",
    "\n",
    "    # Merge the Twitter trend location available dataframe with the\n",
    "    # location info dataframe to create a master list of all\n",
    "    # Twitter Trend locations and associated location information\n",
    "    twitter_trend_locations_df = loc_with_trends_available_df.merge(loc_info_df, how='inner', on='woeid')\n",
    "\n",
    "    # Delete all location information currently in the database 'locations' table\n",
    "\n",
    "    # CHANGED FOR GeoTweet+: Keep all entries - don't delete them!\n",
    "    # db.session.query(Location).delete()\n",
    "    # db.session.commit()\n",
    "\n",
    "    # Write this table of location data to the database 'locations' table\n",
    "    # twitter_trend_locations_df.to_sql( 'locations', con=db.engine, if_exists='append', index=False)\n",
    "    # db.session.commit()\n",
    "\n",
    "    # CHANGED FOR GeoTweet+: Update locations already in the table and add locations that are not\n",
    "    # There is no cross-database SQLAlchemy support for the 'upsert' operation,\n",
    "    # So query for each WOEID in the dataframe and decide if an 'add' or an 'update' is needed...\n",
    "    \n",
    "    # Convert all 'NaN' values to 'None' to avoid issues when updating the database\n",
    "    # Note: Some cities had county_woeid set to \"NaN\", which caused much havoc with db operations\n",
    "    twitter_trend_locations_df = twitter_trend_locations_df.where((pd.notnull(twitter_trend_locations_df)), None)\n",
    "\n",
    "# DEBUG *****************************************************************************************************\n",
    "\n",
    "    global test_df\n",
    "    test_df = twitter_trend_locations_df\n",
    "    \n",
    "    # Loop through all rows in the update dataframe\n",
    "    n_adds = 0\n",
    "    n_updates = 0\n",
    "    for index, row in twitter_trend_locations_df.iterrows():\n",
    "        # Get this row into a dictionary, but exclude primary key 'woeid'\n",
    "        row_dict = row.to_dict()\n",
    "\n",
    "        # pprint(f\"DataFrame: {row['woeid']}\")\n",
    "        result = db.session.query(Location).filter( Location.woeid == row['woeid'] ).first()\n",
    "\n",
    "        if result is None:\n",
    "            # This location is not in the table, so add this entrry to the 'locations' table.\n",
    "            # NOTE: \n",
    "            # Location is the Class mapped to the 'locations' table\n",
    "            # row_dict is a dictionary containing all of the column values for this row as key/value pairs\n",
    "            # The term \"**row_dict\" creates a \"key=value\" parameter for each key/value pair\n",
    "#             print(f\"ADD: DataFrame twitter_trend_locations_df: {row['woeid']} => Database 'locations': New Entry\")\n",
    "            try:\n",
    "                db.session.add( Location(**row_dict) )\n",
    "                db.session.commit()\n",
    "                n_adds += 1\n",
    "                \n",
    "            except:\n",
    "                print(f\">>> Error while attempting to add record to 'locations'\")\n",
    "                db.session.rollback()\n",
    "            \n",
    "        else:\n",
    "            # This location is in the table, so update this entry in the 'locations' table.\n",
    "#             print(f\"UPDATE: DataFrame twitter_trend_locations_df: {row['woeid']} => Database 'locations': {result.woeid}: {result.name_full}\")\n",
    "            \n",
    "            try:\n",
    "                db.session.query(Location).filter( Location.woeid == row['woeid'] ).update( row_dict )\n",
    "                db.session.commit()\n",
    "                n_updates += 1\n",
    "                \n",
    "            except:\n",
    "                print(f\">>> Error while attempting to update record in 'locations'\")\n",
    "                db.session.rollback()\n",
    "                \n",
    "    # Return the total number of entries in the Locations table\n",
    "    num_loc = db.session.query(Location).count()\n",
    "    \n",
    "    print(f\"Adds/Updates complete: Adds: {n_adds}, Updates {n_updates} => Rows in 'locations' table: {num_loc}\")\n",
    "    \n",
    "    return num_loc\n",
    "\n",
    "\n",
    "\n",
    "# # Function Definitions: Twitter Top Trends for Twitter Locations\n",
    "\n",
    "def get_trends_for_loc( a_woeid ):\n",
    "# Get top Twitter trending tweets for a location specified by a WOEID,\n",
    "# flatten the data, and return it as a list of dictionaries\n",
    "\n",
    "    # Import trend availability info into a dataframe\n",
    "    try:\n",
    "        top_trends = api.trends_place( a_woeid )[0]\n",
    "        \n",
    "    except:\n",
    "        # No top trends info available for this WOEID, return False\n",
    "        print(f\"Tweepy API: Problem getting trends information for WOEID {a_woeid}\")\n",
    "        return False\n",
    "    \n",
    "    #pprint(top_trends)\n",
    "    \n",
    "    # Repeat some information that is common for all elements in the trends list\n",
    "    common_info = {}\n",
    "        \n",
    "    # Basic information that should be present for any location\n",
    "    # 'updated_at': Current time in UTC timezone\n",
    "    # 'as_of': '2019-03-26T21:22:42Z',\n",
    "    # 'created_at': '2019-03-26T21:17:18Z',\n",
    "    # 'locations': [{'name': 'Atlanta', 'woeid': 2357024}]\n",
    "    try:\n",
    "        common_info.update( {\n",
    "            'woeid': int(top_trends['locations'][0]['woeid']),\n",
    "            'updated_at': datetime.utcnow(),\n",
    "            'twitter_name': top_trends['locations'][0]['name'],\n",
    "            'twitter_created_at': top_trends['created_at'],\n",
    "            'twitter_as_of': top_trends['as_of']\n",
    "        })\n",
    "                \n",
    "    except:\n",
    "        print(\"Error - basic location information not returned for WOEID{a_woeid}: \", sys.exc_info()[0])\n",
    "   \n",
    "    # Loop through all of the trends and store in an array of dictionary elements\n",
    "    # 'name': 'Jussie Smollett'\n",
    "    # 'promoted_content': None\n",
    "    # 'query': '%22Jussie+Smollett%22'\n",
    "    # 'tweet_volume': 581331\n",
    "    # 'url': 'http://twitter.com/search?q=%22Jussie+Smollett%22'\n",
    "\n",
    "    # Return the trends as an array of flattened dictionaries\n",
    "    trend_info = []\n",
    "\n",
    "    for ti in top_trends['trends']:\n",
    "        \n",
    "        # Put the trend info into a dictionary, starting with the common info\n",
    "        this_trend = common_info.copy()\n",
    "        \n",
    "        # Timezone associated with the location - if available\n",
    "        try:\n",
    "            this_trend.update( {\n",
    "                'twitter_tweet_name': ti['name'],\n",
    "                'twitter_tweet_promoted_content': ti['promoted_content'],\n",
    "                'twitter_tweet_query': ti['query'],\n",
    "                'twitter_tweet_volume': ti['tweet_volume'],\n",
    "                'twitter_tweet_url': ti['url']\n",
    "            })\n",
    "\n",
    "        except:\n",
    "            this_trend.update( {\n",
    "                'twitter_tweet_name': None,\n",
    "                'twitter_tweet_promoted_content': None,\n",
    "                'twitter_tweet_query': None,\n",
    "                'twitter_tweet_volume': None,\n",
    "                'twitter_tweet_url': None\n",
    "            })\n",
    "            \n",
    "        # Append this trend to the list\n",
    "        trend_info.append( this_trend )\n",
    "    \n",
    "    return trend_info\n",
    "\n",
    "\n",
    "\n",
    "def update_db_trends_table():\n",
    "# Function to obtain the list of Twitter locations from the 'locations' DB table.\n",
    "# The function then loops through each location,\n",
    "# obtains the Twitter top trends info, and then appends that data to the 'trends' table.\n",
    "# The function uses rate limit check functions to see if the Twitter API call rate limit\n",
    "# is about to be reached, and if so, delays the next relevant API call until the rate limit\n",
    "# is scheduled to be reset (a period of up to 15minutes) before continuing.\n",
    "#\n",
    "# This function assumes that the 'trends' table in the database has already been configured\n",
    "# and is ready for data.\n",
    "\n",
    "    # Obtain the list of Twitter locations from the 'locations' DB table\n",
    "    loc_list = [ x[0] for x in db.session.query(Location.woeid).all()]\n",
    "    print(f\"Retrieved {len(loc_list)} locations for processing\")\n",
    "    \n",
    "    # Keep track of the actual number of locations\n",
    "    # where trend info was written to the 'trends' table\n",
    "    num_location_trends_written_to_db = 0\n",
    "    \n",
    "    for tw_woeid in loc_list:\n",
    "        print(f\">> Updating trends for location {tw_woeid}\")\n",
    "\n",
    "        # Make sure we haven't hit the rate limit yet\n",
    "        calls_remaining = api_calls_remaining( \"place\" )\n",
    "        time_before_reset = api_time_before_reset( \"place\" )\n",
    "\n",
    "        # If we're close to hitting the rate limit for the trends/place API,\n",
    "        # then wait until the next reset =\n",
    "        # 'time_before_reset' minutes + 1 minute buffer\n",
    "        if (calls_remaining < 2):\n",
    "            print (f\">> Waiting {time_before_reset} minutes due to rate limit\")\n",
    "            time.sleep( (time_before_reset+1) * 60)\n",
    "\n",
    "        # Get trend info for a WOEID location\n",
    "        t_info = get_trends_for_loc(tw_woeid)\n",
    "\n",
    "        try:\n",
    "            # Create a DataFrame\n",
    "            t_info_df = pd.DataFrame.from_dict(t_info)\n",
    "            \n",
    "            # Delete any trends associated with this WOEID\n",
    "            # before appending new trends to the 'trends' table for this WOEID\n",
    "            \n",
    "            # CHANGED FOR GeoTweet+: Keep all entries - don't delete them!\n",
    "            # db.session.query(Trend).filter(Trend.woeid == tw_woeid).delete()\n",
    "            # db.session.commit()\n",
    "\n",
    "            # Append trends for this WOEID to the 'trends' database table\n",
    "            t_info_df.to_sql( 'trends', con=db.engine, if_exisrts='append', index=False)\n",
    "            db.session.commit()\n",
    "\n",
    "            # Increment the count\n",
    "            num_location_trends_written_to_db += 1\n",
    "\n",
    "        except:\n",
    "            print(f\">> Error occurred with location {tw_woeid} while attempting to prepare and write trends data\")\n",
    "            \n",
    "    return num_location_trends_written_to_db\n",
    "\n",
    "\n",
    "def parse_date_range(a_date_range = None):\n",
    "# Function to parse date ranges specified with the Flask API '/period' routes\n",
    "# Note, \n",
    "# Arguments: Single string a_date_range with possible formats:\n",
    "#     a_date_range = \"2019-03-01\"\n",
    "#     a_date_range = \":2019-06-01\"\n",
    "#     a_date_range = \"2019-03-01:2019-06-30\"\n",
    "#     a_date_range = \":\"\n",
    "#     a_date_range = \"all\"\n",
    "#     a_date_range = \"\"\n",
    "#\n",
    "# Returns:\n",
    "#     start_date: Earliest date (inclusive), for use in date comparison\n",
    "#     end_date: Latest date (inclusive), for use in date comparison\n",
    "#     If either date cannot be parsed, an error message is returned\n",
    "\n",
    "    # Max and Min dates\n",
    "    DATE_EARLIEST_POSSIBLE = parser.parse(\"2000-01-01\").date()\n",
    "    DATE_LATEST_POSSIBLE = parser.parse(\"2100-12-31\").date()\n",
    "\n",
    "    # Initialize default return valus - no date restriction\n",
    "    start_date = DATE_EARLIEST_POSSIBLE\n",
    "    end_date = DATE_LATEST_POSSIBLE\n",
    "    \n",
    "    # Parse the argument to obtain the start and end dates - if provided\n",
    "    \n",
    "    # If no argument provided, provide full date range (i.e., no date restriction)\n",
    "    if a_date_range is None:\n",
    "        # Return default values\n",
    "        return (start_date, end_date)\n",
    "\n",
    "    # Prep the date range for additional processing\n",
    "    date_range = a_date_range.strip().lower()\n",
    "    \n",
    "    # Check for \"all\" and similar indications of no date restriction\n",
    "    if date_range == \"all\" or date_range == \"\" or date_range == \":\" :\n",
    "        # Return default values\n",
    "        return (start_date, end_date)\n",
    "    \n",
    "    # Attempt to split the date range (seperator = \":\")\n",
    "    arg_list = a_date_range.split(\":\")\n",
    "    \n",
    "    # If only one argument provided (i.e., no \":\")\n",
    "    # then restrict date range to just that one date\n",
    "    if len(arg_list) == 1:\n",
    "        try:\n",
    "            start_date = parser.parse(arg_list[0]).date()\n",
    "            end_date = start_date\n",
    "            \n",
    "        except ValueError:\n",
    "            start_date = f\"ERROR\"\n",
    "            end_date = start_date\n",
    "\n",
    "        return (start_date, end_date)\n",
    "    \n",
    "    # At least 2 args provided, so assume they are start and end dates\n",
    "    \n",
    "    # Populate start date if the argument is populated, otherwise leave the default\n",
    "    if len(arg_list[0])>0:\n",
    "        try:\n",
    "            start_date = parser.parse(arg_list[0]).date()\n",
    "        except ValueError:\n",
    "            start_date = f\"ERROR\"\n",
    "\n",
    "    # Populate end date if the argument is populated, otherwise leave the default\n",
    "    if len(arg_list[1])>0:\n",
    "        try:\n",
    "            end_date = parser.parse(arg_list[1]).date()\n",
    "        except ValueError:\n",
    "            end_date =  f\"ERROR\"\n",
    "\n",
    "    # Get the date range from the arguments\n",
    "    return (start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flask app route actions - modified for local execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************************\n",
    "# Default route - display the main page\n",
    "# NOTE: Flask expects rendered templates to be in the ./templates folder\n",
    "# @app.route(\"/\")\n",
    "# def home():\n",
    "#     return render_template(\"index.html\")\n",
    "\n",
    "#********************************************************************************\n",
    "# Return information relevant to update\n",
    "# of the 'locations' and 'trends' database tables\n",
    "# @app.route(\"/update\")\n",
    "def update_info():\n",
    "    # Obtain remaining number of API calls for trends/place\n",
    "    api_calls_remaining_place = api_calls_remaining( \"place\")\n",
    "\n",
    "    # Obtain time before rate limits are reset for trends/available\n",
    "    api_time_before_reset_place = api_time_before_reset( \"place\")\n",
    "\n",
    "    # Obtain remaining number of API calls for trends/place\n",
    "    api_calls_remaining_available = api_calls_remaining( \"available\")\n",
    "\n",
    "    # Obtain time before rate limits are reset for trends/available\n",
    "    api_time_before_reset_available = api_time_before_reset( \"available\")\n",
    "\n",
    "    # Count the number of locations in the 'locations' table\n",
    "    n_locations = db.session.query(Location).count()\n",
    "\n",
    "    # Count the number of total trends in the 'trends' table\n",
    "    n_trends = db.session.query(Trend).count()\n",
    "\n",
    "    # Provide the average number of Twitter Trends provided per location\n",
    "    # Use try/except to catch divide by zero\n",
    "    try:\n",
    "        n_trends_per_location_avg = n_trends / n_locations\n",
    "    except ZeroDivisionError:\n",
    "        n_trends_per_location_avg = None\n",
    "\n",
    "    api_info = {\n",
    "        'api_calls_remaining_place': api_calls_remaining_place,\n",
    "        'api_time_before_reset_place': api_time_before_reset_place,\n",
    "        'api_calls_remaining_available': api_calls_remaining_available,\n",
    "        'api_time_before_reset_available': api_time_before_reset_available,\n",
    "        'n_locations': n_locations,\n",
    "        'n_trends': n_trends,\n",
    "        'n_trends_per_location_avg' : n_trends_per_location_avg\n",
    "    }\n",
    "\n",
    "#     return jsonify(api_info)\n",
    "    return api_info\n",
    "\n",
    "#********************************************************************************\n",
    "# Update the 'locations' table via API calls\n",
    "# Note: Typically requires less than 1 minute\n",
    "# @app.route(\"/update/locations\")\n",
    "def update_locations_table():\n",
    "    # Update the locations table through API calls\n",
    "    n_locations = update_db_locations_table()\n",
    "\n",
    "    api_info = {\n",
    "        'n_locations': n_locations\n",
    "    }\n",
    "\n",
    "#     return jsonify(api_info)\n",
    "    return api_info\n",
    "\n",
    "#********************************************************************************\n",
    "# Update the 'trends' table via API calls\n",
    "# Note: Typically requires less than 1 minute if no rate limits\n",
    "#       But require up to 15 minutes if rate limits are in effect\n",
    "# @app.route(\"/update/trends\")\n",
    "def update_trends_table():\n",
    "    # Update the trends table through API calls\n",
    "    n_location_trends = update_db_trends_table()\n",
    "\n",
    "    api_info = {\n",
    "        'n_location_trends': n_location_trends\n",
    "    }\n",
    "\n",
    "#     return jsonify(api_info)\n",
    "    return api_info\n",
    "\n",
    "\n",
    "#********************************************************************************\n",
    "# Return a list of all locations with Twitter Top Trend info\n",
    "# @app.route(\"/locations\")\n",
    "def get_all_locations():\n",
    "    # Query to obtain all locations in the 'locations' table\n",
    "    # REVISED FOR GeoTweet+: Needs to account for retention of locations over time\n",
    "    # results = db.session.query(Location).all()\n",
    "        \n",
    "    # Create a subquery to find the most recent \"updated_at\" record per woeid\n",
    "    loc_subq = db.session.query(Location.woeid, func.max(Location.updated_at) \\\n",
    "                        .label(\"max_updated_at\")) \\\n",
    "                        .group_by(Location.woeid) \\\n",
    "                        .subquery()\n",
    "\n",
    "    results = db.session.query(Location) \\\n",
    "                    .filter( and_( \\\n",
    "                            Location.woeid == loc_subq.c.woeid, \\\n",
    "                            Location.updated_at == loc_subq.c.max_updated_at \\\n",
    "                           )) \\\n",
    "                    .order_by(Location.woeid).all()\n",
    "\n",
    "    loc_list = []\n",
    "    for r in results:\n",
    "        loc_info = {\n",
    "            'updated_at': r.updated_at,\n",
    "            'woeid': r.woeid,\n",
    "            'latitude': r.latitude,\n",
    "            'longitude': r.longitude,\n",
    "            'name_full': r.name_full,\n",
    "            'name_only': r.name_only,\n",
    "            'name_woe': r.name_woe,\n",
    "            'county_name': r.county_name,\n",
    "            'county_name_only': r.county_name_only,\n",
    "            'county_woeid': r.county_woeid,\n",
    "            'state_name': r.state_name,\n",
    "            'state_name_only': r.state_name_only,\n",
    "            'state_woeid': r.state_woeid,\n",
    "            'country_name': r.country_name,\n",
    "            'country_name_only': r.country_name_only,\n",
    "            'country_woeid': r.country_woeid,\n",
    "            'place_type': r.place_type,\n",
    "            'timezone': r.timezone,\n",
    "            'twitter_type': r.twitter_type,\n",
    "            'twitter_country': r.twitter_country,\n",
    "            'tritter_country_code': r.tritter_country_code,\n",
    "            'twitter_name': r.twitter_name,\n",
    "            'twitter_parentid': r.twitter_parentid\n",
    "        }\n",
    "\n",
    "        # loc_info = {\n",
    "        #     'woeid': r.Location.woeid,\n",
    "        #     'latitude': r.Location.latitude,\n",
    "        #     'longitude': r.Location.longitude,\n",
    "        #     'name_full': r.Location.name_full,\n",
    "        #     'name_only': r.Location.name_only,\n",
    "        #     'name_woe': r.Location.name_woe,\n",
    "        #     'county_name': r.Location.county_name,\n",
    "        #     'county_name_only': r.Location.county_name_only,\n",
    "        #     'county_woeid': r.Location.county_woeid,\n",
    "        #     'state_name': r.Location.state_name,\n",
    "        #     'state_name_only': r.Location.state_name_only,\n",
    "        #     'state_woeid': r.Location.state_woeid,\n",
    "        #     'country_name': r.Location.country_name,\n",
    "        #     'country_name_only': r.Location.country_name_only,\n",
    "        #     'country_woeid': r.Location.country_woeid,\n",
    "        #     'place_type': r.Location.place_type,\n",
    "        #     'timezone': r.Location.timezone,\n",
    "        #     'twitter_type': r.Location.twitter_type,\n",
    "        #     'twitter_country': r.Location.twitter_country,\n",
    "        #     'tritter_country_code': r.Location.tritter_country_code,\n",
    "        #     'twitter_parentid': r.Location.twitter_parentid,\n",
    "\n",
    "        #     'twitter_as_of': r.Trend.twitter_as_of,\n",
    "        #     'twitter_created_at': r.Trend.twitter_created_at,\n",
    "        #     'twitter_name': r.Trend.twitter_name,\n",
    "        #     'twitter_tweet_name': r.Trend.twitter_tweet_name,\n",
    "        #     'twitter_tweet_promoted_content': r.Trend.twitter_tweet_promoted_content,\n",
    "        #     'twitter_tweet_query': r.Trend.twitter_tweet_query,\n",
    "        #     'twitter_tweet_url': r.Trend.twitter_tweet_url,\n",
    "        #     'twitter_tweet_volume': r.Trend.twitter_tweet_volume\n",
    "        # }\n",
    "\n",
    "        loc_list.append(loc_info)\n",
    "\n",
    "#     return jsonify(loc_list)\n",
    "    return (loc_list)\n",
    "\n",
    "#********************************************************************************\n",
    "# Return a list of one location  with Twitter Top Trend info with teh specified WOEID\n",
    "# @app.route(\"/locations/<a_woeid>\")\n",
    "def get_info_for_location(a_woeid):\n",
    "    # Query to obtain all locations in the 'locations' table\n",
    "    # REVISED FOR GeoTweet+: Needs to account for retention of locations over time\n",
    "    # results = db.session.query(Location) \\\n",
    "    #                     .filter(Location.woeid == a_woeid) \\\n",
    "    #                     .all()\n",
    "        \n",
    "    # Create a subquery to find the most recent \"updated_at\" record per woeid\n",
    "    loc_subq = db.session.query(Location.woeid, func.max(Location.updated_at) \\\n",
    "                        .label(\"max_updated_at\")) \\\n",
    "                        .group_by(Location.woeid) \\\n",
    "                        .subquery()\n",
    "\n",
    "    results = db.session.query(Location) \\\n",
    "                    .filter( and_( \\\n",
    "                            Location.woeid == a_woeid, \\\n",
    "                            Location.woeid == loc_subq.c.woeid, \\\n",
    "                            Location.updated_at == loc_subq.c.max_updated_at \\\n",
    "                            )) \\\n",
    "                    .order_by(Location.woeid).all()\n",
    "    \n",
    "    loc_list = []\n",
    "    for r in results:\n",
    "        loc_info = {\n",
    "            'updated_at': r.updated_at,\n",
    "            'woeid': r.woeid,\n",
    "            'latitude': r.latitude,\n",
    "            'longitude': r.longitude,\n",
    "            'name_full': r.name_full,\n",
    "            'name_only': r.name_only,\n",
    "            'name_woe': r.name_woe,\n",
    "            'county_name': r.county_name,\n",
    "            'county_name_only': r.county_name_only,\n",
    "            'county_woeid': r.county_woeid,\n",
    "            'state_name': r.state_name,\n",
    "            'state_name_only': r.state_name_only,\n",
    "            'state_woeid': r.state_woeid,\n",
    "            'country_name': r.country_name,\n",
    "            'country_name_only': r.country_name_only,\n",
    "            'country_woeid': r.country_woeid,\n",
    "            'place_type': r.place_type,\n",
    "            'timezone': r.timezone,\n",
    "            'twitter_type': r.twitter_type,\n",
    "            'twitter_country': r.twitter_country,\n",
    "            'tritter_country_code': r.tritter_country_code,\n",
    "            'twitter_name': r.twitter_name,\n",
    "            'twitter_parentid': r.twitter_parentid\n",
    "        }\n",
    "\n",
    "        loc_list.append(loc_info)\n",
    "\n",
    "#     return jsonify(loc_list)\n",
    "    return (loc_list)\n",
    "\n",
    "\n",
    "#********************************************************************************\n",
    "# Return a list of all locations that have the specified tweet in its top trends\n",
    "# and then sort the results by tweet volume in descending order (with NULLs last)\n",
    "# @app.route(\"/locations/tweet/<a_tweet>\")\n",
    "def get_locations_with_tweet(a_tweet):\n",
    "    # Query to obtain all locations in the 'locations' table\n",
    "    # REVISED FOR GeoTweet+: Needs to account for retention of locations over time\n",
    "    results = db.session.query(Trend, Location).join(Location) \\\n",
    "                        .filter(Trend.twitter_tweet_name == a_tweet ) \\\n",
    "                        .order_by( Trend.twitter_tweet_volume.desc().nullslast() ).all()\n",
    "\n",
    "    loc_list = []\n",
    "    for r in results:\n",
    "        #print(f\"Trend Information for {r.Trend.woeid} {r.Location.name_full}: {r.Trend.twitter_tweet_name} {r.Trend.twitter_tweet_volume}\")\n",
    "        loc_info = {\n",
    "            'updated_at': r.Location.updated_at,\n",
    "            'woeid': r.Location.woeid,\n",
    "            'latitude': r.Location.latitude,\n",
    "            'longitude': r.Location.longitude,\n",
    "            'name_full': r.Location.name_full,\n",
    "            'name_only': r.Location.name_only,\n",
    "            'name_woe': r.Location.name_woe,\n",
    "            'county_name': r.Location.county_name,\n",
    "            'county_name_only': r.Location.county_name_only,\n",
    "            'county_woeid': r.Location.county_woeid,\n",
    "            'state_name': r.Location.state_name,\n",
    "            'state_name_only': r.Location.state_name_only,\n",
    "            'state_woeid': r.Location.state_woeid,\n",
    "            'country_name': r.Location.country_name,\n",
    "            'country_name_only': r.Location.country_name_only,\n",
    "            'country_woeid': r.Location.country_woeid,\n",
    "            'place_type': r.Location.place_type,\n",
    "            'timezone': r.Location.timezone,\n",
    "            'twitter_type': r.Location.twitter_type,\n",
    "            'twitter_country': r.Location.twitter_country,\n",
    "            'tritter_country_code': r.Location.tritter_country_code,\n",
    "            'twitter_parentid': r.Location.twitter_parentid,\n",
    "\n",
    "            'twitter_as_of': r.Trend.twitter_as_of,\n",
    "            'twitter_created_at': r.Trend.twitter_created_at,\n",
    "            'twitter_name': r.Trend.twitter_name,\n",
    "            'twitter_tweet_name': r.Trend.twitter_tweet_name,\n",
    "            'twitter_tweet_promoted_content': r.Trend.twitter_tweet_promoted_content,\n",
    "            'twitter_tweet_query': r.Trend.twitter_tweet_query,\n",
    "            'twitter_tweet_url': r.Trend.twitter_tweet_url,\n",
    "            'twitter_tweet_volume': r.Trend.twitter_tweet_volume\n",
    "        }\n",
    "\n",
    "        loc_list.append(loc_info)\n",
    "\n",
    "#     return jsonify(loc_list)\n",
    "    return (loc_list)\n",
    "\n",
    "\n",
    "#********************************************************************************\n",
    "# Return the full list of all trends with Twitter Top Trend info\n",
    "# @app.route(\"/trends\")\n",
    "def get_all_trends():\n",
    "    # Query to obtain all trends in the 'trends' table\n",
    "    # REVISED FOR GeoTweet+: Needs to account for retention of trends over time\n",
    "    # results = db.session.query(Trend).all()\n",
    "\n",
    "    # Create a subquery to find the most recent \"updated_at\" record per woeid\n",
    "    trend_subq = db.session.query(Trend.woeid, func.max(Trend.updated_at) \\\n",
    "                        .label(\"max_updated_at\")) \\\n",
    "                        .group_by(Trend.woeid) \\\n",
    "                        .subquery()\n",
    "\n",
    "    # Query to pull all of the most recent Trends (50 per entry in 'locations' table)\n",
    "    results = db.session.query(Trend) \\\n",
    "                    .filter( and_(\n",
    "                            Trend.woeid == trend_subq.c.woeid, \\\n",
    "                            Trend.updated_at == trend_subq.c.max_updated_at \\\n",
    "                           )) \\\n",
    "                    .all()\n",
    "\n",
    "    \n",
    "    trend_list = []\n",
    "    for r in results:\n",
    "        trend_info = {\n",
    "            'updated_at': r.updated_at,\n",
    "            'woeid': r.woeid,\n",
    "            'twitter_as_of': r.twitter_as_of,\n",
    "            'twitter_created_at': r.twitter_created_at,\n",
    "            'twitter_name': r.twitter_name,\n",
    "            'twitter_tweet_name': r.twitter_tweet_name,\n",
    "            'twitter_tweet_promoted_content': r.twitter_tweet_promoted_content,\n",
    "            'twitter_tweet_query': r.twitter_tweet_query,\n",
    "            'twitter_tweet_url': r.twitter_tweet_url,\n",
    "            'twitter_tweet_volume': r.twitter_tweet_volume\n",
    "        }\n",
    "\n",
    "        trend_list.append(trend_info)\n",
    "\n",
    "#     return jsonify(trend_list)\n",
    "    return (trend_list)\n",
    "\n",
    "#********************************************************************************\n",
    "# Return the full list of Twitter Top Trends for a specific location\n",
    "# and then sort the results by tweet volume in descending order (with NULLs last)\n",
    "# @app.route(\"/trends/<a_woeid>\")\n",
    "def get_trends_for_location(a_woeid):\n",
    "    # Query to obtain all trends in the 'trends' table\n",
    "    # REVISED FOR GeoTweet+: Needs to account for retention of trends over time\n",
    "    # results = db.session.query(Trend).filter(Trend.woeid == a_woeid) \\\n",
    "    #                    .order_by(Trend.twitter_tweet_volume.desc().nullslast() ) \\\n",
    "    #                    .all()\n",
    "\n",
    "    # Create a subquery to find the most recent \"updated_at\" record per woeid\n",
    "    trend_subq = db.session.query(Trend.woeid, func.max(Trend.updated_at) \\\n",
    "                        .label(\"max_updated_at\")) \\\n",
    "                        .group_by(Trend.woeid) \\\n",
    "                        .subquery()\n",
    "\n",
    "    # Query to pull all of the most recent Trends (50 per entry in 'locations' table)\n",
    "    results = db.session.query(Trend) \\\n",
    "                    .filter( and_( \\\n",
    "                            Trend.woeid == a_woeid, \\\n",
    "                            Trend.woeid == trend_subq.c.woeid, \\\n",
    "                            Trend.updated_at == trend_subq.c.max_updated_at \\\n",
    "                           )) \\\n",
    "                    .order_by(Trend.twitter_tweet_volume.desc().nullslast() ) \\\n",
    "                    .all()\n",
    "    \n",
    "    trend_list = []\n",
    "    for r in results:\n",
    "        trend_info = {\n",
    "            'updated_at': r.updated_at,\n",
    "            'woeid': r.woeid,\n",
    "            'twitter_as_of': r.twitter_as_of,\n",
    "            'twitter_created_at': r.twitter_created_at,\n",
    "            'twitter_name': r.twitter_name,\n",
    "            'twitter_tweet_name': r.twitter_tweet_name,\n",
    "            'twitter_tweet_promoted_content': r.twitter_tweet_promoted_content,\n",
    "            'twitter_tweet_query': r.twitter_tweet_query,\n",
    "            'twitter_tweet_url': r.twitter_tweet_url,\n",
    "            'twitter_tweet_volume': r.twitter_tweet_volume\n",
    "        }\n",
    "\n",
    "        trend_list.append(trend_info)\n",
    "\n",
    "#     return jsonify(trend_list)\n",
    "    return (trend_list)\n",
    "\n",
    "#********************************************************************************\n",
    "# Return the top 5 list of Twitter Top Trends for a specific location\n",
    "# and then sort the results by tweet volume in descending order (with NULLs last)\n",
    "# @app.route(\"/trends/top/<a_woeid>\")\n",
    "def get_top_trends_for_location(a_woeid):\n",
    "    # Query to obtain all trends in the 'trends' table\n",
    "    # REVISED FOR GeoTweet+: Needs to account for retention of trends over time\n",
    "    results = db.session.query(Trend) \\\n",
    "                        .filter(Trend.woeid == a_woeid) \\\n",
    "                        .order_by(Trend.twitter_tweet_volume.desc().nullslast() ) \\\n",
    "                        .limit(10).all()\n",
    "\n",
    "    trend_list = []\n",
    "    for r in results:\n",
    "        trend_info = {\n",
    "            'updated_at': r.updated_at,\n",
    "            'woeid': r.woeid,\n",
    "            'twitter_as_of': r.twitter_as_of,\n",
    "            'twitter_created_at': r.twitter_created_at,\n",
    "            'twitter_name': r.twitter_name,\n",
    "            'twitter_tweet_name': r.twitter_tweet_name,\n",
    "            'twitter_tweet_promoted_content': r.twitter_tweet_promoted_content,\n",
    "            'twitter_tweet_query': r.twitter_tweet_query,\n",
    "            'twitter_tweet_url': r.twitter_tweet_url,\n",
    "            'twitter_tweet_volume': r.twitter_tweet_volume\n",
    "        }\n",
    "\n",
    "        trend_list.append(trend_info)\n",
    "\n",
    "#     return jsonify(trend_list)\n",
    "    return (trend_list)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/19 04:46:21\n"
     ]
    }
   ],
   "source": [
    "# Perform a query\n",
    "# Albuquerque: 2352824\n",
    "# United States: 23424977\n",
    "q_woeid = 2352824\n",
    "results = db.session.query(Trend).filter(Trend.woeid == q_woeid) \\\n",
    "                        .order_by(Trend.twitter_tweet_volume.desc().nullslast() ).limit(10).all()\n",
    "\n",
    "# Print results\n",
    "trend_list = []\n",
    "for r in results:\n",
    "    trend_info = {\n",
    "        'updated_at': r.updated_at,\n",
    "        'woeid': r.woeid,\n",
    "        'twitter_as_of': r.twitter_as_of,\n",
    "        'twitter_created_at': r.twitter_created_at,\n",
    "        'twitter_name': r.twitter_name,\n",
    "        'twitter_tweet_name': r.twitter_tweet_name,\n",
    "        'twitter_tweet_promoted_content': r.twitter_tweet_promoted_content,\n",
    "        'twitter_tweet_query': r.twitter_tweet_query,\n",
    "        'twitter_tweet_url': r.twitter_tweet_url,\n",
    "        'twitter_tweet_volume': r.twitter_tweet_volume\n",
    "    }\n",
    "\n",
    "    trend_list.append(trend_info)\n",
    "\n",
    "# pprint ( trend_list[0]['updated_at'].strftime(\"%a %m/%d/%y %H:%M:%S\") )\n",
    "print ( trend_list[0]['updated_at'].strftime(\"%x %X\") )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "[{'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': '#GameofThrones',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%23GameofThrones',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%23GameofThrones',\n",
      "  'twitter_tweet_volume': 2809280.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'Arya',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': 'Arya',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=Arya',\n",
      "  'twitter_tweet_volume': 1726986.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': '#BattleOfWinterfell',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%23BattleOfWinterfell',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%23BattleOfWinterfell',\n",
      "  'twitter_tweet_volume': 831962.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'Stark',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': 'Stark',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=Stark',\n",
      "  'twitter_tweet_volume': 794959.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'Night King',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%22Night+King%22',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%22Night+King%22',\n",
      "  'twitter_tweet_volume': 584673.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'Bran',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': 'Bran',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=Bran',\n",
      "  'twitter_tweet_volume': 307463.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'Cersei',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': 'Cersei',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=Cersei',\n",
      "  'twitter_tweet_volume': 191045.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'Theon',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': 'Theon',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=Theon',\n",
      "  'twitter_tweet_volume': 189423.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'Ghost',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': 'Ghost',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=Ghost',\n",
      "  'twitter_tweet_volume': 165112.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': '#DemThrones',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%23DemThrones',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%23DemThrones',\n",
      "  'twitter_tweet_volume': 164612.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'Melisandre',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': 'Melisandre',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=Melisandre',\n",
      "  'twitter_tweet_volume': 161864.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'NOT TODAY',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%22NOT+TODAY%22',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%22NOT+TODAY%22',\n",
      "  'twitter_tweet_volume': 146948.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'Jorah',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': 'Jorah',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=Jorah',\n",
      "  'twitter_tweet_volume': 130001.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'Lyanna Mormont',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%22Lyanna+Mormont%22',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%22Lyanna+Mormont%22',\n",
      "  'twitter_tweet_volume': 115481.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'Jon Snow',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%22Jon+Snow%22',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%22Jon+Snow%22',\n",
      "  'twitter_tweet_volume': 106282.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'The Battle of Winterfell',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%22The+Battle+of+Winterfell%22',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%22The+Battle+of+Winterfell%22',\n",
      "  'twitter_tweet_volume': 87421.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'White Walkers',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%22White+Walkers%22',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%22White+Walkers%22',\n",
      "  'twitter_tweet_volume': 77238.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': '#GOTS8E3',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%23GOTS8E3',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%23GOTS8E3',\n",
      "  'twitter_tweet_volume': 71427.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'Dothraki',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': 'Dothraki',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=Dothraki',\n",
      "  'twitter_tweet_volume': 69295.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'Episode 3',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%22Episode+3%22',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%22Episode+3%22',\n",
      "  'twitter_tweet_volume': 61492.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'God of Death',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%22God+of+Death%22',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%22God+of+Death%22',\n",
      "  'twitter_tweet_volume': 58004.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': '#ForTheThrone',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%23ForTheThrone',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%23ForTheThrone',\n",
      "  'twitter_tweet_volume': 51531.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'Beric',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': 'Beric',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=Beric',\n",
      "  'twitter_tweet_volume': 43668.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'Drogon',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': 'Drogon',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=Drogon',\n",
      "  'twitter_tweet_volume': 41099.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'Lady Mormont',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%22Lady+Mormont%22',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%22Lady+Mormont%22',\n",
      "  'twitter_tweet_volume': 39238.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'Westeros',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': 'Westeros',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=Westeros',\n",
      "  'twitter_tweet_volume': 27860.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'Targaryen',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': 'Targaryen',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=Targaryen',\n",
      "  'twitter_tweet_volume': 27694.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': '#NotToday',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%23NotToday',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%23NotToday',\n",
      "  'twitter_tweet_volume': 22991.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': '#AmericanIdol',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%23AmericanIdol',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%23AmericanIdol',\n",
      "  'twitter_tweet_volume': 22374.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': '#ThronesYall',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%23ThronesYall',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%23ThronesYall',\n",
      "  'twitter_tweet_volume': 22289.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'Rhaegal',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': 'Rhaegal',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=Rhaegal',\n",
      "  'twitter_tweet_volume': 19450.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'Grey Worm',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%22Grey+Worm%22',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%22Grey+Worm%22',\n",
      "  'twitter_tweet_volume': 19215.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'The Hound',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%22The+Hound%22',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%22The+Hound%22',\n",
      "  'twitter_tweet_volume': 17880.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': '#GOT8',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%23GOT8',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%23GOT8',\n",
      "  'twitter_tweet_volume': 17776.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'Azor Ahai',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%22Azor+Ahai%22',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%22Azor+Ahai%22',\n",
      "  'twitter_tweet_volume': 17402.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'Unsullied',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': 'Unsullied',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=Unsullied',\n",
      "  'twitter_tweet_volume': 16104.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'Red Woman',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%22Red+Woman%22',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%22Red+Woman%22',\n",
      "  'twitter_tweet_volume': 15621.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': '#90DayFiance',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%2390DayFiance',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%2390DayFiance',\n",
      "  'twitter_tweet_volume': 13535.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'Viserion',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': 'Viserion',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=Viserion',\n",
      "  'twitter_tweet_volume': 13321.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'Lord of Light',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%22Lord+of+Light%22',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%22Lord+of+Light%22',\n",
      "  'twitter_tweet_volume': 13047.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': \"King's Landing\",\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%22King%27s+Landing%22',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%22King%27s+Landing%22',\n",
      "  'twitter_tweet_volume': 12165.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'House Mormont',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%22House+Mormont%22',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%22House+Mormont%22',\n",
      "  'twitter_tweet_volume': 10671.0,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': '#TheChi',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%23TheChi',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%23TheChi',\n",
      "  'twitter_tweet_volume': None,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'The Long Night',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%22The+Long+Night%22',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%22The+Long+Night%22',\n",
      "  'twitter_tweet_volume': None,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'Tyrion and Sansa',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%22Tyrion+and+Sansa%22',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%22Tyrion+and+Sansa%22',\n",
      "  'twitter_tweet_volume': None,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'Jon and Dany',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%22Jon+and+Dany%22',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%22Jon+and+Dany%22',\n",
      "  'twitter_tweet_volume': None,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': '#TalktheThrones',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%23TalktheThrones',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%23TalktheThrones',\n",
      "  'twitter_tweet_volume': None,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': '#Barry',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%23Barry',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%23Barry',\n",
      "  'twitter_tweet_volume': None,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'Sansa and Tyrion',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': '%22Sansa+and+Tyrion%22',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=%22Sansa+and+Tyrion%22',\n",
      "  'twitter_tweet_volume': None,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977},\n",
      " {'twitter_as_of': '2019-04-29T04:46:29Z',\n",
      "  'twitter_created_at': '2019-04-29T04:39:51Z',\n",
      "  'twitter_name': 'United States',\n",
      "  'twitter_tweet_name': 'GRRM',\n",
      "  'twitter_tweet_promoted_content': None,\n",
      "  'twitter_tweet_query': 'GRRM',\n",
      "  'twitter_tweet_url': 'http://twitter.com/search?q=GRRM',\n",
      "  'twitter_tweet_volume': None,\n",
      "  'updated_at': datetime.datetime(2019, 4, 29, 4, 46, 28, 155248),\n",
      "  'woeid': 23424977}]\n"
     ]
    }
   ],
   "source": [
    "# Perform a query\n",
    "# Albuquerque: 2352824\n",
    "# United States: 23424977\n",
    "q_woeid = 23424977\n",
    "retval = get_trends_for_location(q_woeid)\n",
    "print(len(retval))\n",
    "pprint(retval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify Basic DB functions using Local Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db.session.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db.session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_dict = test_df.iloc[38].to_dict()\n",
    "# sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row_dict=sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row_dict['updated_at'] = parser.parse('2019-04-28 00:35:00.000001')\n",
    "# row_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # print(f\"Dictionary to Add or Update:\")\n",
    "# # pprint(row_dict)\n",
    "\n",
    "# result = db.session.query(Location).filter( Location.woeid == int(row_dict['woeid']) ).first()\n",
    "# n_adds = 0\n",
    "# n_updates = 0\n",
    "# if result is None:\n",
    "#     # This location is not in the table, so add this entrry to the 'locations' table.\n",
    "#     # NOTE: \n",
    "#     # Location is the Class mapped to the 'locations' table\n",
    "#     # row_dict is a dictionary containing all of the column values for this row as key/value pairs\n",
    "#     # The term \"**row_dict\" creates a \"key=value\" parameter for each key/value pair\n",
    "#     n_add += 1\n",
    "#     print(f\"ADD: DataFrame: {row_dict['woeid']} => Database 'locations': New Entry\")\n",
    "#     db.session.add( Location(**row_dict) )\n",
    "#     db.session.commit()\n",
    "\n",
    "# else:\n",
    "#     # This location is in the table, so update this entry in the 'locations' table.\n",
    "#     n_updates += 1\n",
    "#     print(f\"UPDATE: DataFrame: {row_dict['woeid']} => Database 'locations': {result.woeid}: {result.name_full}\")\n",
    "    \n",
    "#     # WHY IS THIS UPDATE FAILING WITH 'ProgrammingError' ??\n",
    "#     db.session.query(Location).filter( Location.woeid == int(row_dict['woeid']) ).update( row_dict )\n",
    "#     db.session.commit()\n",
    "        \n",
    "# # Return the total number of entries in the Locations table\n",
    "# num_loc = db.session.query(Location).count()\n",
    "# print(f\"Adds/Updates complete: Adds: {n_adds}, Updates {n_updates} => Rows in 'locations' table: {num_loc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FYI, checking for any 'NaN' values in the dataframe\n",
    "# fixed_test_df[ pd.notnull(fixed_test_df['county_woeid']) == False ]['county_woeid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser.parse('2019-04-28 17:37:37.664148')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# homeloc_dict = {\n",
    "#     'twitter_country': 'United States',\n",
    "#     'tritter_country_code': 'US',\n",
    "#     'twitter_name': 'Carol Stream',\n",
    "#     'twitter_parentid': 23424977,\n",
    "#     'woeid': 123456,\n",
    "#     'updated_at': parser.parse('2019-04-28 17:37:37.664148'),\n",
    "#     'twitter_type': 'Town',\n",
    "#     'country_name': 'United States',\n",
    "#     'country_name_only': 'United States',\n",
    "#     'country_woeid': 23424977,\n",
    "#     'county_name': 'Carol Stream, Illinois, United States',\n",
    "#     'county_name_only': 'DuPage County',\n",
    "#     'county_woeid': 12589279,\n",
    "#     'latitude': 35.105,\n",
    "#     'longitude': -106.647,\n",
    "#     'name_full': 'Carol Stream, Illinois, United States',\n",
    "#     'name_only': 'Carol Stream',\n",
    "#     'name_woe': 'Carol Stream',\n",
    "#     'place_type': 'locality',\n",
    "#     'state_name': 'Illinois, United States',\n",
    "#     'state_name_only': 'Illinois',\n",
    "#     'state_woeid': 2347590.0,\n",
    "#     'timezone': 'America/Chicago'\n",
    "# }\n",
    "# homeloc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Update locations table\n",
    "# n_locations = update_db_locations_table()\n",
    "# print(n_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "2352824 => 2019-04-29 01:10:20.129726\n",
      "2357024 => 2019-04-29 01:10:20.129726\n",
      "2357536 => 2019-04-29 01:10:20.129726\n",
      "2358820 => 2019-04-29 01:10:20.129726\n",
      "2359991 => 2019-04-29 01:10:20.129726\n",
      "2364559 => 2019-04-29 01:10:20.129726\n",
      "2367105 => 2019-04-29 01:10:20.129726\n",
      "2378426 => 2019-04-29 01:10:20.129726\n",
      "2379574 => 2019-04-29 01:10:20.129726\n",
      "2380358 => 2019-04-29 01:10:20.129726\n",
      "2381475 => 2019-04-29 01:10:20.129726\n",
      "2383489 => 2019-04-29 01:10:20.129726\n",
      "2383660 => 2019-04-29 01:10:20.129726\n",
      "2388929 => 2019-04-29 01:10:20.129726\n",
      "2391279 => 2019-04-29 01:10:20.129726\n",
      "2391585 => 2019-04-29 01:10:20.129726\n",
      "2397816 => 2019-04-29 01:10:20.129726\n",
      "2407517 => 2019-04-29 01:10:20.129726\n",
      "2414469 => 2019-04-29 01:10:20.129726\n",
      "2418046 => 2019-04-29 01:10:20.129726\n",
      "2423945 => 2019-04-29 01:10:20.129726\n",
      "2424766 => 2019-04-29 01:10:20.129726\n",
      "2427032 => 2019-04-29 01:10:20.129726\n",
      "2428184 => 2019-04-29 01:10:20.129726\n",
      "2428344 => 2019-04-29 01:10:20.129726\n",
      "2430683 => 2019-04-29 01:10:20.129726\n",
      "2436704 => 2019-04-29 01:10:20.129726\n",
      "2441472 => 2019-04-29 01:10:20.129726\n",
      "2442047 => 2019-04-29 01:10:20.129726\n",
      "2442327 => 2019-04-29 01:10:20.129726\n",
      "2449323 => 2019-04-29 01:10:20.129726\n",
      "2449808 => 2019-04-29 01:10:20.129726\n",
      "2450022 => 2019-04-29 01:10:20.129726\n",
      "2451822 => 2019-04-29 01:10:20.129726\n",
      "2452078 => 2019-04-29 01:10:20.129726\n",
      "2457170 => 2019-04-29 01:10:20.129726\n",
      "2458410 => 2019-04-29 01:10:20.129726\n",
      "2458833 => 2019-04-29 01:10:20.129726\n",
      "2459115 => 2019-04-29 01:10:20.129726\n",
      "2460389 => 2019-04-29 01:10:20.129726\n",
      "2464592 => 2019-04-29 01:10:20.129726\n",
      "2465512 => 2019-04-29 01:10:20.129726\n",
      "2466256 => 2019-04-29 01:10:20.129726\n",
      "2471217 => 2019-04-29 01:10:20.129726\n",
      "2471390 => 2019-04-29 01:10:20.129726\n",
      "2473224 => 2019-04-29 01:10:20.129726\n",
      "2475687 => 2019-04-29 01:10:20.129726\n",
      "2477058 => 2019-04-29 01:10:20.129726\n",
      "2478307 => 2019-04-29 01:10:20.129726\n",
      "2480894 => 2019-04-29 01:10:20.129726\n",
      "2486340 => 2019-04-29 01:10:20.129726\n",
      "2486982 => 2019-04-29 01:10:20.129726\n",
      "2487610 => 2019-04-29 01:10:20.129726\n",
      "2487796 => 2019-04-29 01:10:20.129726\n",
      "2487889 => 2019-04-29 01:10:20.129726\n",
      "2487956 => 2019-04-29 01:10:20.129726\n",
      "2488042 => 2019-04-29 01:10:20.129726\n",
      "2490383 => 2019-04-29 01:10:20.129726\n",
      "2503713 => 2019-04-29 01:10:20.129726\n",
      "2503863 => 2019-04-29 01:10:20.129726\n",
      "2508428 => 2019-04-29 01:10:20.129726\n",
      "2512636 => 2019-04-29 01:10:20.129726\n",
      "2514815 => 2019-04-29 01:10:20.129726\n",
      "23424977 => 2019-04-29 01:10:20.129726\n"
     ]
    }
   ],
   "source": [
    "# Query to get the max (i.e., most recent) \"updated_at\" values per location\n",
    "loc_max_update_at_list = db.session.query(Location.woeid, func.max(Location.updated_at) \\\n",
    "                                        .label(\"max_updated_at\")) \\\n",
    "                                        .group_by(Location.woeid) \\\n",
    "                                        .order_by(Location.woeid) \\\n",
    "                                        .all()\n",
    "print( len(loc_max_update_at_list) )\n",
    "for m in loc_max_update_at_list:\n",
    "    print( f\"{m.woeid} => {m.max_updated_at}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Database 'locations': 2352824: Albuquerque, New Mexico, United States => updated_at: 2019-04-29 01:10:20.129726\n"
     ]
    }
   ],
   "source": [
    "# Create a subquery to find the most recent \"updated_at\" record per woeid\n",
    "loc_subq = db.session.query(Location.woeid, func.max(Location.updated_at) \\\n",
    "                        .label(\"max_updated_at\")) \\\n",
    "                        .group_by(Location.woeid) \\\n",
    "                        .subquery()\n",
    "\n",
    "# results = db.session.query(Location).filter( Location.updated_at == max_update_time ).all()\n",
    "\n",
    "results = db.session.query(Location) \\\n",
    "                    .filter( and_( \\\n",
    "                            Location.woeid == 2352824, \\\n",
    "                            Location.woeid == loc_subq.c.woeid, \\\n",
    "                            Location.updated_at == loc_subq.c.max_updated_at \\\n",
    "                           )) \\\n",
    "                    .order_by(Location.woeid).all()\n",
    "\n",
    "print( len(results) )\n",
    "\n",
    "for r in results:\n",
    "    print(f\"Database 'locations': {r.woeid}: {r.name_full} => updated_at: {r.updated_at}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Location Albuquerque, New Mexico, United States [updated_at: 2019-04-29 01:10:20.129726>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # db.session.rollback()\n",
    "# trend_max_update_at_list = db.session.query(Trend.woeid, func.max(Trend.updated_at) \\\n",
    "#                                         .label(\"max_updated_at\")) \\\n",
    "#                                         .group_by(Trend.woeid) \\\n",
    "#                                         .order_by(Trend.woeid) \\\n",
    "#                                         .all()\n",
    "# print( len(trend_max_update_at_list) )\n",
    "# for m in trend_max_update_at_list:\n",
    "#     print( f\"{m.woeid} => {m.max_updated_at}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "Database 'locations': 2352824: Albuquerque #GameofThrones => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Arya => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque #BattleOfWinterfell => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Endgame => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque #ThankYouAvengers => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Night King => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Bran => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Cersei => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque #DemThrones => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque #GOTS8E3 => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Ghost => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Theon => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque NOT TODAY => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Dothraki => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Lyanna Mormont => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Stark => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Jorah => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Jon Snow => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Melisandre => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Lady Mormont => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque God of Death => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Targaryen => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Westeros => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Drogon => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Sansa and Tyrion => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque House Mormont => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque The Hound => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque White Walkers => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Rhaegal => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Jon and Dany => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Azor Ahai => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque King's Landing => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque The Long Night => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque GRRM => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Episode 3 => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque The Battle of Winterfell => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Beric => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Red Woman => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Lord of Light => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Tyrion and Sansa => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Grey Worm => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Unsullied => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque #NotToday => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque #ForTheThrone => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque #GOT8 => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque #ThronesYall => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque #TalktheThrones => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque #Barry => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque #AmericanIdol => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque #90DayFiance => updated_at: 2019-04-29 04:46:21.259684\n"
     ]
    }
   ],
   "source": [
    "# Create a subquery to find the most recent \"updated_at\" record per woeid\n",
    "trend_subq = db.session.query(Trend.woeid, func.max(Trend.updated_at) \\\n",
    "                        .label(\"max_updated_at\")) \\\n",
    "                        .group_by(Trend.woeid) \\\n",
    "                        .subquery()\n",
    "\n",
    "# Query to pull all of the most recent Trends (50 per entry in 'locations' table)\n",
    "results = db.session.query(Trend) \\\n",
    "                    .filter( and_( \\\n",
    "                            Trend.woeid == 2352824, \\\n",
    "                            Trend.woeid == trend_subq.c.woeid, \\\n",
    "                            Trend.updated_at == trend_subq.c.max_updated_at \\\n",
    "                           )) \\\n",
    "                    .order_by(Trend.updated_at.desc(), Trend.woeid).all()\n",
    "\n",
    "print( len(results) )\n",
    "\n",
    "for r in results:\n",
    "    print(f\"Database 'locations': {r.woeid}: {r.twitter_name} {r.twitter_tweet_name} => updated_at: {r.updated_at}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_date_range: 'UTC' => q_start_date 'ERROR', q_end_date 'ERROR''\n",
      "a_date_range: 'None' => q_start_date '2000-01-01', q_end_date '2100-12-31''\n",
      "a_date_range: 'all' => q_start_date '2000-01-01', q_end_date '2100-12-31''\n",
      "a_date_range: '' => q_start_date '2000-01-01', q_end_date '2100-12-31''\n",
      "a_date_range: ':' => q_start_date '2000-01-01', q_end_date '2100-12-31''\n",
      "a_date_range: '2019-03-01' => q_start_date '2019-03-01', q_end_date '2019-03-01''\n",
      "a_date_range: '2019-03-01:' => q_start_date '2019-03-01', q_end_date '2100-12-31''\n",
      "a_date_range: ':2019-06-01' => q_start_date '2000-01-01', q_end_date '2019-06-01''\n",
      "a_date_range: '2019-03-01:2019-06-30' => q_start_date '2019-03-01', q_end_date '2019-06-30''\n",
      "a_date_range: ':UTC' => q_start_date '2000-01-01', q_end_date 'ERROR''\n"
     ]
    }
   ],
   "source": [
    "# Testing if this is working for all combinations\n",
    "for a_date_range in [ \"UTC\", None, \"all\", \"\", \":\", \"2019-03-01\", \"2019-03-01:\", \":2019-06-01\", \"2019-03-01:2019-06-30\", \":UTC\"]:\n",
    "    (q_start_date, q_end_date) = parse_date_range(a_date_range)\n",
    "    print(f\"a_date_range: '{a_date_range}' => q_start_date '{q_start_date}', q_end_date '{q_end_date}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_end_date == \"ERROR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc_d = date(2019, 6, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc_dt = datetime(2019, 6, 30, 12, 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc_d >= abc_dt.date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_date_range: '4/29/19:4/30/19' => q_start_date '2019-04-29', q_end_date '2019-04-30'\n",
      "2019-04-29 to 2019-04-30\n",
      "50\n",
      "Database 'locations': 2352824: Albuquerque #GameofThrones => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Arya => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque #BattleOfWinterfell => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Endgame => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque #ThankYouAvengers => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Night King => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Bran => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Cersei => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque #DemThrones => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque #GOTS8E3 => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Ghost => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Theon => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque NOT TODAY => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Dothraki => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Lyanna Mormont => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Stark => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Jorah => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Jon Snow => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Melisandre => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Lady Mormont => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque God of Death => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Targaryen => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Westeros => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Drogon => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Sansa and Tyrion => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque House Mormont => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque The Hound => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque White Walkers => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Rhaegal => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Jon and Dany => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Azor Ahai => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque King's Landing => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque The Long Night => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque GRRM => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Episode 3 => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque The Battle of Winterfell => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Beric => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Red Woman => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Lord of Light => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Tyrion and Sansa => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Grey Worm => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque Unsullied => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque #NotToday => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque #ForTheThrone => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque #GOT8 => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque #ThronesYall => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque #TalktheThrones => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque #Barry => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque #AmericanIdol => updated_at: 2019-04-29 04:46:21.259684\n",
      "Database 'locations': 2352824: Albuquerque #90DayFiance => updated_at: 2019-04-29 04:46:21.259684\n"
     ]
    }
   ],
   "source": [
    "a_date_range = \"4/29/19:4/30/19\"\n",
    "q_start_date, q_end_date = parse_date_range(a_date_range)\n",
    "print(f\"a_date_range: '{a_date_range}' => q_start_date '{q_start_date}', q_end_date '{q_end_date}'\")\n",
    "\n",
    "print( f\"{q_start_date} to {q_end_date}\")\n",
    "\n",
    "trend_subq = db.session.query(Trend.woeid, func.max(Trend.updated_at).label(\"max_updated_at\")) \\\n",
    "                        .group_by(Trend.woeid) \\\n",
    "                        .subquery()\n",
    "\n",
    "# Query to pull all of the most recent Trends (50 per entry in 'locations' table)\n",
    "results = db.session.query(Trend) \\\n",
    "                    .filter( and_( \\\n",
    "                            Trend.woeid == 2352824, \\\n",
    "                            Trend.updated_at >= q_start_date, \\\n",
    "                            Trend.updated_at < q_end_date, \\\n",
    "                           )) \\\n",
    "                    .order_by(Trend.updated_at.desc(), Trend.woeid).all()\n",
    "\n",
    "print( len(results) )\n",
    "\n",
    "for r in results:\n",
    "    print(f\"Database 'locations': {r.woeid}: {r.twitter_name} {r.twitter_tweet_name} => updated_at: {r.updated_at}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].my_location.woeid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[338].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Update trends table\n",
    "# n_location_trends = update_db_trends_table()\n",
    "# print(n_location_trends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all locations\n",
    "retval = get_all_locations()\n",
    "print(len(retval))\n",
    "pprint(retval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read one location - e.g., 2352824 (Albuquerque)\n",
    "retval = get_info_for_location(2352824)\n",
    "print(len(retval))\n",
    "pprint(retval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read all trends\n",
    "retval = get_all_trends()\n",
    "print(len(retval))\n",
    "pprint(retval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read trends for one location - e.g., 2352824 (Albuquerque)\n",
    "retval = get_trends_for_location(2352824)\n",
    "print(len(retval))\n",
    "pprint(retval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read only the top trends for one location - e.g., 2352824 (Albuquerque)\n",
    "retval = get_top_trends_for_location(2352824)\n",
    "print(len(retval))\n",
    "pprint(retval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read all locations with specified tweet in its trends list - e.g., \"#SriLanka\"\n",
    "retval = get_locations_with_tweet(\"#SriLanka\")\n",
    "print(len(retval))\n",
    "pprint(retval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check on the query of locations by tweet - e.g., \"Carlos Vela\" appeared for 2358820 (Baltimore)\n",
    "retval = get_trends_for_location(2358820)\n",
    "print(len(retval))\n",
    "pprint(retval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
