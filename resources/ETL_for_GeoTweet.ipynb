{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2 - GeoTweet\n",
    "\n",
    "@Author Jeffery Brown (daddyjab)<br>\n",
    "@Date 3/25/19<br>\n",
    "@File ETL_for_GeoTweet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import tweepy\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime \n",
    "from dateutil import tz\n",
    "import requests\n",
    "from pprint import pprint\n",
    "\n",
    "# Database dependencies\n",
    "# Imports the method used for connecting to DBs\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "# Imports the methods needed to abstract classes into tables\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "\n",
    "# Allow us to declare column types\n",
    "from sqlalchemy import Column, Integer, String, Float, ForeignKey\n",
    "\n",
    "# API Keys\n",
    "from api_config import *\n",
    "\n",
    "# Twitter API\n",
    "# key_twitter_tweetquestor_consumer_api_key\n",
    "# key_twitter_tweetquestor_consumer_api_secret_key\n",
    "# key_twitter_tweetquestor_access_token\n",
    "# key_twitter_tweetquestor_access_secret_token\n",
    "\n",
    "# Flickr API\n",
    "# key_flicker_infoquestor_key\n",
    "# key_flicker_infoquestor_secret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Configuration for `locations` and `trends` Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the database using SQLAlchemy\n",
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database schema for Twitter 'locations' table\n",
    "class Location(Base):\n",
    "    __tablename__ = 'locations'\n",
    "    \n",
    "    # Defining the columns for the table 'locations',\n",
    "    # which will hold all of the locations in the U.S. for which\n",
    "    # top trends data is available, as well as location specific\n",
    "    # info like latitude/longitude\n",
    "    id = Column( Integer, primary_key = True)\n",
    "    woeid = Column( Integer )\n",
    "    twitter_country = Column( String(100) )\n",
    "    tritter_country_code = Column( String(10) )\n",
    "    twitter_name = Column( String(250) )\n",
    "    twitter_parentid = Column( Integer )\n",
    "    twitter_type = Column( String(50) )\n",
    "    country_name = Column( String(250) )\n",
    "    country_name_only = Column( String(250) )\n",
    "    country_woeid = Column( Integer )\n",
    "    county_name = Column( String(250) )\n",
    "    county_name_only = Column( String(250) )\n",
    "    county_woeid = Column( Integer )\n",
    "    latitude = Column( Float )\n",
    "    longitude = Column( Float )\n",
    "    name_full = Column( String(250) )\n",
    "    name_only = Column( String(250) )\n",
    "    name_woe = Column( String(250) )\n",
    "    place_type = Column( String(250) )\n",
    "    state_name = Column( String(250) )\n",
    "    state_name_only = Column( String(250) )\n",
    "    state_woeid = Column( Integer )\n",
    "    timezone = Column( String(250) )\n",
    "    \n",
    "# Database schema for Twitter 'trends' table\n",
    "class Trend(Base):\n",
    "    __tablename__ = 'trends'\n",
    "    \n",
    "    # Defining the columns for the table 'trends',\n",
    "    # which will hold all of the top trends associated with\n",
    "    # locations in the 'locations' table\n",
    "    id = Column( Integer, primary_key = True)\n",
    "    woeid = Column( Integer )\n",
    "    twitter_as_of = Column( String(100) )\n",
    "    twitter_created_at = Column( String(100) )\n",
    "    twitter_name = Column( String(250) )\n",
    "    twitter_tweet_name = Column( String(250) )\n",
    "    twitter_tweet_promoted_content = Column( String(250) )\n",
    "    twitter_tweet_query = Column( String(250) )\n",
    "    twitter_tweet_url = Column( String(250) )\n",
    "    twitter_tweet_volume = Column( Float )\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Setup for `twitter_trends.db` Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an engine that stores data in the local directory's SQLite file\n",
    "# 'data/twitter_trends.db'.\n",
    "# NOTE: Since this Jupyter notebook  is running in the ./resources folder\n",
    "# the path to the database is a little different\n",
    "db_path_jupyter_notebook = \"sqlite:///../data/twitter_trends.db\"\n",
    "\n",
    "# But the Flask app will run from the main folder\n",
    "db_path_flask_app = \"sqlite:///data/twitter_trends.db\"\n",
    "\n",
    "engine = create_engine(db_path_jupyter_notebook)\n",
    "\n",
    "# Create all table in the engine\n",
    "# (The equivalent of Create Table statements in raw SQL)\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "# Bind the engine to the metadata of the Base class so that the\n",
    "# declaratives can be accessed through a DBSession instance\n",
    "Base.metadata.bind = engine\n",
    "DBSession = sessionmaker(bind=engine)\n",
    "\n",
    "# A DBSession() instance establishes all conversations with the database\n",
    "# and represents a \"staging zone\" for all the objects loaded into the\n",
    "# database session object. Any change made against the objects in the\n",
    "# session won't be persisted into the database until you call\n",
    "# session.commit(). If you're not happy about the changes, you can\n",
    "# revert all of them back to the last commit by calling\n",
    "# session.rollback()\n",
    "session = DBSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweepy Setup for Twitter API Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Tweepy API Authentication to access Twitter\n",
    "auth = tweepy.OAuthHandler(key_twitter_tweetquestor_consumer_api_key, key_twitter_tweetquestor_consumer_api_secret_key)\n",
    "auth.set_access_token(key_twitter_tweetquestor_access_token, key_twitter_tweetquestor_access_secret_token)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definitions: Twitter API Rate Limit Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_calls_remaining( a_api, a_type = \"place\"):\n",
    "# Return the number of Twitter API calls remaining\n",
    "# for the specified API type:\n",
    "# 'place': Top 10 trending topics for a WOEID\n",
    "# 'closest': Locations near a specificed lat/long for which Twitter has trending topic info\n",
    "# 'available': Locations for which Twitter has topic info\n",
    "\n",
    "    # Get Twitter rate limit information using the Tweepy API\n",
    "    rate_limits = a_api.rate_limit_status()\n",
    "    \n",
    "    # Focus on the rate limits for trends calls\n",
    "    trends_limits = rate_limits['resources']['trends']\n",
    "    \n",
    "    # Return the remaining requests available for the\n",
    "    # requested type of trends query (or \"\" if not a valid type)\n",
    "    try:\n",
    "        remaining = trends_limits[ f\"/trends/{a_type}\" ]['remaining']\n",
    "        print(f\"Twitter API 'trends/{a_type}' - API Calls Remaining: {remaining}\")\n",
    "\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "    return remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_time_before_reset( a_api, a_type = \"place\"):\n",
    "# Return the number of minutes until the Twitter API is reset\n",
    "# for the specified API type:\n",
    "# 'place': Top 10 trending topics for a WOEID\n",
    "# 'closest': Locations near a specificed lat/long for which Twitter has trending topic info\n",
    "# 'available': Locations for which Twitter has topic info\n",
    "\n",
    "    # Get Twitter rate limit information using the Tweepy API\n",
    "    rate_limits = a_api.rate_limit_status()\n",
    "    \n",
    "    # Focus on the rate limits for trends calls\n",
    "    trends_limits = rate_limits['resources']['trends']\n",
    "    \n",
    "    \n",
    "    # Return the reset time for the\n",
    "    # requested type of trends query (or \"\" if not a valid type)\n",
    "    try:\n",
    "        reset_ts = trends_limits[ f\"/trends/{a_type}\" ]['reset']\n",
    "    except:\n",
    "        return -1\n",
    "        \n",
    "    # Calculate the remaining time using datetime methods to\n",
    "    # get the UTC time from the POSIX timestamp\n",
    "    reset_utc = datetime.utcfromtimestamp(reset_ts)\n",
    "    \n",
    "    # Current the current time\n",
    "    current_utc = datetime.utcnow()\n",
    "    \n",
    "    # Calculate the number of seconds remaining,\n",
    "    # Assumption: reset time will be >= current time\n",
    "    time_before_reset = (reset_utc - current_utc).total_seconds() / 60.0\n",
    "    \n",
    "    # Tell the datetime object that it's in UTC time zone since \n",
    "    # datetime objects are 'naive' by default\n",
    "    reset_utc = reset_utc.replace(tzinfo = tz.tzutc() )\n",
    "    \n",
    "    # Convert time zone\n",
    "    reset_local = reset_utc.astimezone( tz.tzlocal() )\n",
    "\n",
    "    # Tell the datetime object that it's in UTC time zone since \n",
    "    # datetime objects are 'naive' by default\n",
    "    current_utc = current_utc.replace(tzinfo = tz.tzutc() )\n",
    "    \n",
    "    # Convert time zone\n",
    "    current_local = current_utc.astimezone( tz.tzlocal() )\n",
    "    print(f\"Twitter API 'trends/{a_type}' - Time Before Rate Limit Reset: {time_before_reset:.1f}: Reset Time: {reset_local.strftime('%Y-%m-%d %H:%M:%S')}, Local Time: {current_local.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    # Return the time before reset (in minutes)\n",
    "    return time_before_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definitions: Twitter Locations with Available Trends Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loc_with_trends_available_to_df( a_api ):\n",
    "# Get locations that have trends data from a api.trends_available() call,\n",
    "# flatten the data, and create a dataframe\n",
    "\n",
    "    # Obtain the WOEID locations for which Twitter Trends info is available\n",
    "    try:\n",
    "        trends_avail = a_api.trends_available()\n",
    "        \n",
    "    except TweepError as e:\n",
    "        # No top trends info available for this WOEID, return False\n",
    "        print(f\"Error obtaining top trends for WOEID {a_woeid}: \", e)\n",
    "        return False\n",
    "    \n",
    "    # Import trend availability info into a dataframe\n",
    "    trends_avail_df = pd.DataFrame.from_dict(trends_avail, orient='columns')\n",
    "\n",
    "    # Retain only locations in the U.S.\n",
    "    trends_avail_df = trends_avail_df[ (trends_avail_df['countryCode'] == \"US\") ]\n",
    "        \n",
    "    # Reset the index\n",
    "    trends_avail_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Flatten the dataframe by unpacking the placeType column information into separate columns\n",
    "    trends_avail_df['twitter_type'] = trends_avail_df['placeType'].map( lambda x: x['name'])\n",
    "\n",
    "    # Remove unneeded fields\n",
    "    trends_avail_df.drop(['placeType', 'url' ], axis='columns' , inplace = True)\n",
    "\n",
    "    # Rename the fields\n",
    "    trends_avail_df.rename(columns={\n",
    "        'woeid': 'woeid',\n",
    "        'country': 'twitter_country',\n",
    "        'countryCode': 'tritter_country_code',\n",
    "        'name': 'twitter_name',\n",
    "        'parentid': 'twitter_parentid' }, inplace=True)\n",
    "    \n",
    "    return trends_avail_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_info( a_woeid ):\n",
    "# Use Flickr API call to get location information associated with a Yahoo! WOEID\n",
    "# Note: Yahoo! no longer supports this type of lookup! :(\n",
    "\n",
    "    # Setup the Flickr API base URL\n",
    "    flickr_api_base_url = f\"https://api.flickr.com/services/rest/?method=flickr.places.getInfo&api_key={key_flicker_infoquestor_key}&format=json&nojsoncallback=1&woe_id=\"\n",
    "\n",
    "    # Populate the WOEID and convert to string format\n",
    "    woeid_to_search = str(a_woeid)\n",
    "    \n",
    "    # Build the full URL for API REST request\n",
    "    flickr_api_url = flickr_api_base_url + woeid_to_search\n",
    "\n",
    "    try:\n",
    "        # Get the REST response, which will be in JSON format\n",
    "        response = requests.get(url=flickr_api_url)\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(\"Error obtaining location information for WOEID {a_woeid}: \", e)\n",
    "        return False\n",
    "    \n",
    "    # Parse the json\n",
    "    location_data = response.json()\n",
    "    \n",
    "    # Check for failure to locate the information\n",
    "    if (location_data['stat'] == 'fail'):\n",
    "        print(f\"Error finding location WOEID {a_woeid}: {location_data['message']}\")\n",
    "        \n",
    "        \n",
    "    #pprint(location_data)\n",
    "    \n",
    "    # Return just a useful subset of the location info as flattened dictionary\n",
    "    key_location_info = {}\n",
    "    \n",
    "    # Basic information that should be present for any location\n",
    "    try:\n",
    "        key_location_info.update( {\n",
    "            'woeid': int(location_data['place']['woeid']),\n",
    "            'name_woe': location_data['place']['woe_name'],\n",
    "            'name_full': location_data['place']['name'],\n",
    "            'name_only': location_data['place']['name'].split(\",\")[0].strip(),\n",
    "            'place_type': location_data['place']['place_type'],\n",
    "            'latitude': float(location_data['place']['latitude']),\n",
    "            'longitude': float(location_data['place']['longitude']),\n",
    "        })\n",
    "                \n",
    "    except:\n",
    "        print(\"Error - basic location information not returned for WOEID{a_woeid}: \", sys.exc_info()[0])\n",
    "    \n",
    "    # Timezone associated with the location - if available\n",
    "    try:\n",
    "        key_location_info.update( {\n",
    "            'timezone': location_data['place']['timezone']  \n",
    "        })\n",
    "        \n",
    "    except:\n",
    "        key_location_info.update( {\n",
    "            'timezone': None\n",
    "        })\n",
    "        \n",
    "    # County associated with the location - if available\n",
    "    try:\n",
    "        key_location_info.update( {\n",
    "            'county_name': location_data['place']['county']['_content'],\n",
    "            'county_name_only': location_data['place']['county']['_content'].split(\",\")[0].strip(),\n",
    "            'county_woeid': int(location_data['place']['county']['woeid']),\n",
    "        })\n",
    "    except:\n",
    "        key_location_info.update( {\n",
    "            'county_name': None,\n",
    "            'county_name_only': None,\n",
    "            'county_woeid': None,\n",
    "        })\n",
    "        \n",
    "    # State associated with the location - if available\n",
    "    try:\n",
    "        key_location_info.update( {\n",
    "            'state_name': location_data['place']['region']['_content'],\n",
    "            'state_name_only': location_data['place']['region']['_content'].split(\",\")[0].strip(),\n",
    "            'state_woeid': int(location_data['place']['region']['woeid']),\n",
    "        })\n",
    "    except:\n",
    "        key_location_info.update( {\n",
    "            'state_name': None,\n",
    "            'state_name_only': None,\n",
    "            'state_woeid': None,\n",
    "        })\n",
    "        \n",
    "    # Country associated with the location - if available\n",
    "    try:\n",
    "        key_location_info.update( {\n",
    "            'country_name': location_data['place']['country']['_content'],\n",
    "            'country_name_only': location_data['place']['country']['_content'].split(\",\")[0].strip(),\n",
    "            'country_woeid': int(location_data['place']['country']['woeid']),\n",
    "        })\n",
    "    except:\n",
    "        key_location_info.update( {\n",
    "            'country_name': None,\n",
    "            'country_name_only': None,\n",
    "            'country_woeid': None, \n",
    "        })\n",
    "    \n",
    "    return key_location_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_db_locations_table(a_api, a_engine)\n",
    "# Function to update the list of Twitter locations in the'locations' DB table.\n",
    "# This function uses a Twitter API to get the list of locations for which top trends\n",
    "# information is available.  It then uses a Flickr API to obtain location details for\n",
    "# each of these Twitter specified locations.  A merge is then performed of the two\n",
    "# DataFrames, resulting in a single dataframe that is used to update the 'locations' table.\n",
    "# NOTE: The Twitter 'trends/available' API call is not rate limited.\n",
    "#\n",
    "# This function assumes that the 'locations' table in the database has already been configured\n",
    "# and is ready for data.\n",
    "\n",
    "    # Flatten the Twitter Trends results and populate in a Dataframe\n",
    "    loc_with_trends_available_df = get_loc_with_trends_available_to_df( a_api )\n",
    "\n",
    "    # Use the get_location_info() function to add location info (from Flickr)\n",
    "    # for each location (Twitter WOEID) that has trend info\n",
    "    loc_info_list =  list( loc_with_trends_available_df['woeid'].apply( get_location_info ) )\n",
    "\n",
    "    # Create a DataFrame from the location info list\n",
    "    loc_info_df = pd.DataFrame.from_dict(loc_info_list)\n",
    "\n",
    "    # Merge the Twitter trend location available dataframe with the\n",
    "    # location info dataframe to create a master list of all\n",
    "    # Twitter Trend locations and associated location information\n",
    "    twitter_trend_locations_df = loc_with_trends_available_df.merge(loc_info_df, how='inner', on='woeid')\n",
    "\n",
    "    # Delete all location information currently in the database 'locations' table\n",
    "    session.query(Location).delete()\n",
    "    session.commit()\n",
    "\n",
    "    # Write this table of location data to the database 'locations' table\n",
    "    twitter_trend_locations_df.to_sql( 'locations', con=a_engine, if_exists='append', index=False)\n",
    "\n",
    "    # Print an informative message regarding the update just performed\n",
    "    q_results = session.query(Location).all()\n",
    "    print(f\"Updated {len(q_results)} locations\")\n",
    "\n",
    "    for row in q_results:\n",
    "        print(row.woeid, row.name_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definitions: Twitter Top Trends for Twitter Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trends_for_loc( a_api, a_woeid ):\n",
    "# Get top Twitter trending tweets for a location specified by a WOEID,\n",
    "# flatten the data, and return it as a list of dictionaries\n",
    "\n",
    "    # Import trend availability info into a dataframe\n",
    "    try:\n",
    "        top_trends = a_api.trends_place( a_woeid )[0]\n",
    "        \n",
    "    except TweepError as e:\n",
    "        # No top trends info available for this WOEID, return False\n",
    "        print(f\"Error obtaining top trends for WOEID {a_woeid}: \", e)\n",
    "        return False\n",
    "    \n",
    "    #pprint(top_trends)\n",
    "    \n",
    "    # Repeat some information that is common for all elements in the trends list\n",
    "    common_info = {}\n",
    "        \n",
    "    # Basic information that should be present for any location\n",
    "    # 'as_of': '2019-03-26T21:22:42Z',\n",
    "    # 'created_at': '2019-03-26T21:17:18Z',\n",
    "    # 'locations': [{'name': 'Atlanta', 'woeid': 2357024}]\n",
    "    try:\n",
    "        common_info.update( {\n",
    "            'woeid': int(top_trends['locations'][0]['woeid']),\n",
    "            'twitter_name': top_trends['locations'][0]['name'],\n",
    "            'twitter_created_at': top_trends['created_at'],\n",
    "            'twitter_as_of': top_trends['as_of']\n",
    "        })\n",
    "                \n",
    "    except:\n",
    "        print(\"Error - basic location information not returned for WOEID{a_woeid}: \", sys.exc_info()[0])\n",
    "   \n",
    "    # Loop through all of the trends and store in an array of dictionary elements\n",
    "    # 'name': 'Jussie Smollett'\n",
    "    # 'promoted_content': None\n",
    "    # 'query': '%22Jussie+Smollett%22'\n",
    "    # 'tweet_volume': 581331\n",
    "    # 'url': 'http://twitter.com/search?q=%22Jussie+Smollett%22'\n",
    "\n",
    "    # Return the trends as an array of flattened dictionaries\n",
    "    trend_info = []\n",
    "\n",
    "    for ti in top_trends['trends']:\n",
    "        \n",
    "        # Put the trend info into a dictionary, starting with the common info\n",
    "        this_trend = common_info.copy()\n",
    "        \n",
    "        # Timezone associated with the location - if available\n",
    "        try:\n",
    "            this_trend.update( {\n",
    "                'twitter_tweet_name': ti['name'],\n",
    "                'twitter_tweet_promoted_content': ti['promoted_content'],\n",
    "                'twitter_tweet_query': ti['query'],\n",
    "                'twitter_tweet_volume': ti['tweet_volume'],\n",
    "                'twitter_tweet_url': ti['url']\n",
    "            })\n",
    "\n",
    "        except:\n",
    "            this_trend.update( {\n",
    "                'twitter_tweet_name': None,\n",
    "                'twitter_tweet_promoted_content': None,\n",
    "                'twitter_tweet_query': None,\n",
    "                'twitter_tweet_volume': None,\n",
    "                'twitter_tweet_url': None\n",
    "            })\n",
    "            \n",
    "        # Append this trend to the list\n",
    "        trend_info.append( this_trend )\n",
    "    \n",
    "    return trend_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def update_db_trends_table(a_api, a_engine):\n",
    "# Function to obtain the list of Twitter locations from the 'locations' DB table.\n",
    "# The function then loops through each location,\n",
    "# obtains the Twitter top trends info, and then appends that data to the 'trends' table.\n",
    "# The function uses rate limit check functions to see if the Twitter API call rate limit\n",
    "# is about to be reached, and if so, delays the next relevant API call until the rate limit\n",
    "# is scheduled to be reset (a period of up to 15minutes) before continuing.\n",
    "#\n",
    "# This function assumes that the 'trends' table in the database has already been configured\n",
    "# and is ready for data.\n",
    "\n",
    "    # Obtain the list of Twitter locations from the 'locations' DB table\n",
    "    loc_list = [ x[0] for x in session.query(Location.woeid).all()]\n",
    "    print(f\"Retrieved {len(loc_list)} locations for processing\")\n",
    "    \n",
    "    # Keep track of the actual number of locations\n",
    "    # where trend info was written to the 'trends' table\n",
    "    num_location_trends_written_to_db = 0\n",
    "    \n",
    "    for tw_woeid in loc_list:\n",
    "        print(f\">> Updating trends for location {tw_woeid}\")\n",
    "\n",
    "        # Make sure we haven't hit the rate limit yet\n",
    "        calls_remaining = api_calls_remaining( a_api, \"place\" )\n",
    "        time_before_reset = api_time_before_reset( a_api, \"place\")\n",
    "\n",
    "        # If we're close to hitting the rate limit for the trends/place API,\n",
    "        # then wait until the next reset =\n",
    "        # 'time_before_reset' minutes + 1 minute buffer\n",
    "        if (calls_remaining < 2):\n",
    "            print (f\">> Waiting {time_before_reset} minutes due to rate limit\")\n",
    "            time.sleep( (time_before_reset+1) * 60)\n",
    "\n",
    "        # Get trend info for a WOEID location\n",
    "        t_info = get_trends_for_loc(a_api, tw_woeid)\n",
    "\n",
    "        try:\n",
    "            # Create a DataFrame\n",
    "            t_info_df = pd.DataFrame.from_dict(t_info)\n",
    "            \n",
    "            # Delete any trends associated with this WOEID\n",
    "            # before appending new trends to the 'trends' table for this WOEID\n",
    "            session.query(Trend).filter(Trend.woeid == tw_woeid).delete()\n",
    "            session.commit()\n",
    "\n",
    "            # Append trends for this WOEID to the 'trends' database table\n",
    "            t_info_df.to_sql( 'trends', con=a_engine, if_exists='append', index=False)\n",
    "            \n",
    "            # Increment the count\n",
    "            num_location_trends_written_to_db += 1\n",
    "\n",
    "        except:\n",
    "            print(f\">> Error occurred with location {tw_woeid} while attempting to prepare and write trends data\")\n",
    "            \n",
    "    return num_location_trends_written_to_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Call to Update Twitter Location `locations` Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a call to the function that fully updates the database 'locations' table\n",
    "# Note: This function deletes the location data before the updated information is added\n",
    "# locations_written_to_db = update_db_locations_table(api, engine)\n",
    "# locations_written_to_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Call to Update Twitter Top Trends `trends` Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This is a call to the function that fully updates the database 'trends' table\n",
    "# for the locations in the 'locations' table\n",
    "# Note: This function deletes the trends data for each location before new information is added\n",
    "# trends_written_to_db = update_db_trends_table(api, engine)\n",
    "# trends_written_to_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
